#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
RisKVA é£é™©è¯„ä¼°æ¨¡å‹è®­ç»ƒè„šæœ¬

æœ¬è„šæœ¬ç”¨äºè®­ç»ƒåŸºäºè§†è§‰è¯­è¨€æ¨¡å‹çš„æˆ¿å±‹åˆ†æˆ·æ£€æŸ¥é£é™©è¯„ä¼°æ¨¡å‹ã€‚
æ”¯æŒå¤šæ¨¡æ€è¾“å…¥ï¼ˆå›¾åƒ+æ–‡æœ¬ï¼‰ï¼Œèƒ½å¤Ÿåˆ†æç¼ºé™·å¹¶è¯„ä¼°é£é™©ç­‰çº§ã€‚

ä¸»è¦åŠŸèƒ½ï¼š
- æ•°æ®é¢„å¤„ç†å’Œæ ¼å¼è½¬æ¢
- å¤šæ¨¡æ€æ¨¡å‹è®­ç»ƒ
- å†…å­˜ä¼˜åŒ–å’Œæ˜¾å­˜ç®¡ç†
- åˆ†å¸ƒå¼è®­ç»ƒæ”¯æŒ

ä½œè€…: RisKVA Team
åˆ›å»ºæ—¶é—´: 2024
"""

# æ ‡å‡†åº“å¯¼å…¥
import gc
import json
import logging
import os
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple, Union

# ç¬¬ä¸‰æ–¹åº“å¯¼å…¥
import torch
from accelerate import PartialState
from datasets import Dataset, DatasetDict, load_dataset  # type: ignore
from PIL import Image
from transformers import (
    AutoModelForImageTextToText, 
    AutoProcessor, 
    LlavaForConditionalGeneration,
    PreTrainedModel
)

# TRL ç›¸å…³å¯¼å…¥
from trl import (  # type: ignore
    ModelConfig,
    ScriptArguments,
    SFTConfig,
    SFTTrainer,
    TrlParser,
    get_kbit_device_map,
    get_peft_config,
    get_quantization_config,
)

# =============================================================================
# æ•°æ®é›†é¢„å¤„ç†æ¨¡å—
# =============================================================================

def prepare_dataset(
    dataset: DatasetDict, 
    dataset_path: str, 
    dataset_train_split: str, 
    templates: Optional[Dict[str, Any]] = None
) -> DatasetDict:
    """ todo æ·»åŠ å›¾åƒå¢å¼ºå¤„ç†
    å‡†å¤‡è®­ç»ƒæ•°æ®é›†ï¼Œå°†åŸå§‹æ•°æ®è½¬æ¢ä¸ºæ¨¡å‹å¯ç”¨çš„æ ¼å¼ã€‚
    
    Args:
        dataset (DatasetDict): åŸå§‹æ•°æ®é›†
        dataset_path (str): æ•°æ®é›†æ–‡ä»¶è·¯å¾„ï¼Œç”¨äºå®šä½å›¾åƒæ–‡ä»¶
        dataset_train_split (str): è®­ç»ƒé›†åˆ†å‰²åç§°ï¼Œé€šå¸¸ä¸º'train'
        templates (Optional[Dict[str, Any]]): å¯é€‰çš„æ¨¡æ¿é…ç½®ï¼Œæš‚æœªä½¿ç”¨
        
    Returns:
        DatasetDict: è½¬æ¢åçš„æ•°æ®é›†ï¼ŒåŒ…å«messageså’Œimageså­—æ®µ
        
    Note:
        è½¬æ¢åçš„æ•°æ®æ ¼å¼ç¬¦åˆTRL SFTTrainerçš„è¦æ±‚ï¼š
        - messages: å¯¹è¯æ ¼å¼çš„æ–‡æœ¬æ•°æ®
        - images: PILå›¾åƒå¯¹è±¡åˆ—è¡¨
    """
    logging.info(f"å¼€å§‹å‡†å¤‡æ•°æ®é›†ï¼Œè®­ç»ƒåˆ†å‰²: {dataset_train_split}")
    
    # è½¬æ¢è®­ç»ƒé›†æ•°æ®
    train_data = transform_dataset(dataset[dataset_train_split], dataset_path)
    
    # åˆ›å»ºæ–°çš„æ•°æ®é›†å¯¹è±¡
    new_train_dataset = Dataset.from_dict(train_data)
    
    # æ„å»ºæ–°çš„DatasetDict
    new_dataset = DatasetDict({
        dataset_train_split: new_train_dataset
    })
    
    logging.info(f"æ•°æ®é›†å‡†å¤‡å®Œæˆï¼Œæ ·æœ¬æ•°é‡: {len(new_train_dataset)}")
    return new_dataset


def transform_dataset(dataset_split: DatasetDict, dataset_path: str) -> Dict[str, List[Any]]:
    """
    è½¬æ¢æ•°æ®é›†åˆ†å‰²ä¸ºæ¨¡å‹è®­ç»ƒæ ¼å¼ã€‚
    
    å°†åŸå§‹æ•°æ®é›†ä¸­çš„æ¯ä¸ªæ ·æœ¬è½¬æ¢ä¸ºåŒ…å«å¯¹è¯æ¶ˆæ¯å’Œå›¾åƒçš„æ ¼å¼ï¼Œ
    é€‚ç”¨äºå¤šæ¨¡æ€è¯­è¨€æ¨¡å‹è®­ç»ƒã€‚
    
    Args:
        dataset_split (DatasetDict): æ•°æ®é›†çš„æŸä¸ªåˆ†å‰²ï¼ˆå¦‚è®­ç»ƒé›†ï¼‰
        dataset_path (str): æ•°æ®é›†è·¯å¾„ï¼Œç”¨äºæ„å»ºå›¾åƒæ–‡ä»¶çš„å®Œæ•´è·¯å¾„
        
    Returns:
        Dict[str, List[Any]]: è½¬æ¢åçš„æ•°æ®ï¼ŒåŒ…å«ï¼š
            - messages: å¯¹è¯æ ¼å¼çš„æ¶ˆæ¯åˆ—è¡¨
            - images: å¯¹åº”çš„å›¾åƒåˆ—è¡¨
            
    Note:
        ä¸ºäº†ä¼˜åŒ–å†…å­˜ä½¿ç”¨ï¼Œå‡½æ•°ä¼šåœ¨å¤„ç†è¿‡ç¨‹ä¸­ä¸»åŠ¨æ¸…ç†ä¸­é—´å˜é‡
        å¹¶è§¦å‘åƒåœ¾å›æ”¶ã€‚
    """
    logging.info(f"å¼€å§‹è½¬æ¢æ•°æ®é›†ï¼Œæ ·æœ¬æ•°é‡: {len(dataset_split)}")
    
    transformed_data = {
        'messages': [],
        'images': []
    }
    
    for idx, sample in enumerate(dataset_split):
        try:
            formatted = format_sample(sample, dataset_path)
            transformed_data['messages'].append(formatted['messages'])
            transformed_data['images'].append(formatted['images'])
            
            # æ¸…ç†ä¸­é—´å˜é‡ï¼Œé‡Šæ”¾å†…å­˜
            del formatted
            
            # æ¯å¤„ç†1000ä¸ªæ ·æœ¬æ‰“å°ä¸€æ¬¡è¿›åº¦
            if (idx + 1) % 1000 == 0:
                logging.info(f"å·²å¤„ç†æ ·æœ¬: {idx + 1}/{len(dataset_split)}")
                
        except Exception as e:
            logging.error(f"å¤„ç†æ ·æœ¬ {idx} æ—¶å‡ºé”™: {e}")
            continue
    
    # ä¸»åŠ¨è§¦å‘åƒåœ¾å›æ”¶
    gc.collect()
    logging.info("æ•°æ®é›†è½¬æ¢å®Œæˆ")
    return transformed_data

    
def format_sample(sample: Dict[str, Any], dataset_path: str) -> Dict[str, Any]:
    """
    å°†å•ä¸ªæ•°æ®æ ·æœ¬è½¬æ¢ä¸ºæ¨¡å‹è®­ç»ƒæ‰€éœ€çš„å¯¹è¯æ ¼å¼ã€‚
    
    æ­¤å‡½æ•°æ˜¯æ•°æ®é¢„å¤„ç†çš„æ ¸å¿ƒï¼Œå°†åŸå§‹çš„æˆ¿å±‹æ£€æŸ¥æ•°æ®è½¬æ¢ä¸º
    å¤šæ¨¡æ€å¯¹è¯æ ¼å¼ï¼ŒåŒ…æ‹¬ç”¨æˆ·é—®é¢˜å’ŒåŠ©æ‰‹å›ç­”ã€‚
    
    Args:
        sample (Dict[str, Any]): åŸå§‹æ•°æ®æ ·æœ¬ï¼ŒåŒ…å«å›¾åƒè·¯å¾„å’Œæ–‡æœ¬å­—æ®µ
        dataset_path (str): æ•°æ®é›†æ ¹è·¯å¾„ï¼Œç”¨äºæ„å»ºå›¾åƒçš„å®Œæ•´è·¯å¾„
        
    Returns:
        Dict[str, Any]: æ ¼å¼åŒ–åçš„æ ·æœ¬ï¼ŒåŒ…å«ï¼š
            - messages: ç”¨æˆ·å’ŒåŠ©æ‰‹çš„å¯¹è¯æ¶ˆæ¯
            - images: PILå›¾åƒå¯¹è±¡åˆ—è¡¨
            
    Note:
        æ”¯æŒæœ‰å›¾åƒå’Œæ— å›¾åƒä¸¤ç§æƒ…å†µï¼š
        - æœ‰å›¾åƒï¼šè¦æ±‚æ¨¡å‹åŸºäºå›¾åƒè¿›è¡Œåˆ†æ
        - æ— å›¾åƒï¼šæä¾›ç¼ºé™·æ–‡æœ¬æè¿°ï¼Œè¦æ±‚åŸºäºæ–‡æœ¬åˆ†æ
    """
    # 1. åŠ è½½å›¾åƒ
    all_image_paths = sample.get('all_image_paths', '[]')
    images = get_images_from_paths(all_image_paths, dataset_path)
    
    # 2. æå–æ ·æœ¬å­—æ®µï¼Œæä¾›é»˜è®¤å€¼
    defect_description = sample.get('defect_description_text', 'æœªçŸ¥ç¼ºé™·')
    risk_detail = sample.get('risk_detail', 'é£é™©è¯¦æƒ…æœªæä¾›')
    correction_suggestion = sample.get('correction_suggestion', 'å»ºè®®æœªæä¾›')
    risk_level_original = sample.get('risk_level_original', 'é£é™©ç­‰çº§ï¼ˆåŸæœ¬ï¼‰æœªæä¾›')
    risk_level_current = sample.get('risk_level_current', 'é£é™©ç­‰çº§ï¼ˆç°åœ¨ï¼‰æœªæä¾›')
    
    # 3. æ„å»ºç”¨æˆ·é—®é¢˜
    image_count = sample.get('image_count', 0)
    base_instruction = '''ä½œä¸ºæˆ¿å±‹åˆ†æˆ·æ£€æŸ¥ä¸“å®¶ï¼Œä½ ç°åœ¨æ­£åœ¨è¿›è¡Œåˆ†æˆ·æ£€æŸ¥åˆ†æã€‚è¯·ä¾æ®å›¾åƒå¯è§è¯æ®ä¸é¡¹ç›®é€‚ç”¨è§„èŒƒè¿›è¡Œåˆ¤æ–­ã€‚

ã€é¡¹ç›®é˜¶æ®µä¸è¯„ä¼°èŒƒå›´ã€‘
- é˜¶æ®µï¼šTIS å®Œå·¥é˜¶æ®µã€‚
- è¯„ä¼°èŒƒå›´ï¼šä»¥â€œæ–½å·¥â€ä¸ºä¸»ï¼Œæ¶‰åŠéƒ¨ä½/ä¸“ä¸šåŒ…æ‹¬ï¼šä¸»ä½“ã€å®‰è£…ã€è£…é¥°è£…ä¿®ã€é—¨çª—ã€éš”å¢™ã€é˜²æ°´ã€ä¿æ¸©ã€‚
- æ£€æŸ¥å†…å®¹ç±»åˆ«ï¼šè´¨é‡è¡Œä¸ºä¸å·¥ç¨‹å®ä½“ä¸ºé‡ç‚¹ã€‚

ã€åˆ†æˆ·æ£€æŸ¥å¯¹è±¡ä¸åŒºåŸŸã€‘
- æ£€æŸ¥åŒºåŸŸã€éƒ¨ä½ï¼šæ¥¼ã€åœ°ä¸‹å®¤ï¼›æˆ·å†…ã€å…¬åŒºæ¥¼å±‚ã€å±‹é¢ã€å¤–å¢™ã€åœ°ä¸‹å®¤ç­‰ã€‚

ã€éå…¨è£…ä¿®ä½å®…åˆ†æˆ·æ£€æŸ¥è¦ç‚¹ã€‘
- å®¤å†…åœ°é¢ï¼šå¤–è§‚è´¨é‡ã€åœ°é¢é«˜å·®ã€ç»†éƒ¨è´¨é‡ã€å¡åº¦ã€è¸¢è„šçº¿ã€‚
- å®¤å†…å¢™é¢/é¡¶æ£šï¼šå¤–è§‚è´¨é‡ã€ç»†éƒ¨è´¨é‡ã€æ¸—æ¼ã€‚
- å»ºç­‘é—¨çª—ï¼šçŒ«çœ¼/é—¨é“ƒã€é—¨æ¡†/é—¨æ‰‡/é—¨è½´/é—¨å¸ã€é—¨é”/æŠŠæ‰‹ã€çª—æ¡†/çª—æ‰‡ï¼ˆå«é˜²è„±è½è£…ç½®ï¼‰ã€ç»ç’ƒã€å¯†å°æ¡ã€é˜²æ¸—æ¼ã€çª—æŠŠæ‰‹ã€çª—å°æ–½å·¥ä¸é˜²æŠ¤ã€‚
- æŠ¤æ æ æ†ï¼šæˆå“è´¨é‡ã€å®‰è£…è´¨é‡ã€å®‰è£…é«˜åº¦ã€å‚ç›´æ†é—´è·ã€‚
- ç»™æ’æ°´ï¼šç®¡é“ã€é¾™å¤´/è§’é˜€ã€åœ°æ¼å®‰è£…ä¸å¡åº¦ã€æ£€ä¿®é—¨ã€‚
- å®¤å†…ç”µæ°”ï¼šå¼ºç”µç®±å¤–è§‚ä¸å›è·¯å®‰è£…ã€å¼€å…³/æ’åº§å®‰è£…ä¸é«˜åº¦ã€å›è·¯æ§åˆ¶æ ‡è¯†ã€‚
- é€šé£ä¸ç©ºè°ƒï¼šæ’æ°”/æ’çƒŸå£ã€ç©ºè°ƒé¢„ç•™æ´å£ã€‚
- å…¶ä»–ï¼šçƒŸé“å¤–è§‚è´¨é‡ã€æ­¢é€†é˜€ç­‰ã€‚

ã€å…¨è£…ä¿®ä½å®…åˆ†æˆ·æ£€æŸ¥è¦ç‚¹ã€‘
- åœ°æ¿é“ºè£…ï¼šå®‰è£…æ–¹å¼ã€ç‰¢å›ºæ€§ã€è¸¢è„šçº¿ã€‚
- ç“·ç –/çŸ³æï¼šé—¨æ§›çŸ³/çª—å°çŸ³å¤–è§‚ä¸é«˜åº¦ã€è¡¨è§‚è´¨é‡ã€é“ºè´´æ–¹å¼ã€æ¥ç¼é«˜ä½ä¸å¡«å……ã€ç©ºé¼“ã€ç»†éƒ¨è´¨é‡ã€åœ°é¢å¡åº¦ä¸æ¸…æ´ã€‚
- æ¶‚æ–™/å¢™çº¸/è½¯åŒ…ï¼šåŸºå±‚åŸºé¢ã€æ¶‚åˆ·è´¨é‡ä¸æ•ˆæœã€å¼‚è‰²åˆ†ç•Œã€é“ºè´´è´¨é‡ã€ç»†éƒ¨è´¨é‡ã€‚
- åŠé¡¶/æ©±æŸœ/æ‰¶æ‰‹ï¼šå¤–è§‚å®Œæ•´æ€§ã€ç»†éƒ¨è´¨é‡ã€å¨å«å‡€é«˜ã€é—¨æ¿/æŸœèº«/æŠ½å±‰ä¸é…ä»¶ã€å°é¢æ°´å¹³åº¦ã€æ”¶è¾¹æ”¶å£ã€è¸¢è„šçº¿ã€çª—å¸˜ç›’æ¥ç¼ã€æŠ¤æ ä¸æŠ¤æ‰‹ã€çª—å°æ¿å®‰è£…åŠè¡¨è§‚ä¸æ¥ç¼å¤„ç†ã€é—¨çª—å¥—å®‰è£…ä¸è¡¨è§‚ã€‚
- é—¨çª—å®‰è£…ï¼šçŒ«çœ¼/é—¨é“ƒã€é—¨æ¡†/é—¨æ‰‡/é—¨çª—å¥—ã€é—¨è½´/é—¨å¸ã€é—¨é”/æŠŠæ‰‹ã€çª—æ¡†/çª—æ‰‡ï¼ˆé˜²è„±è½ï¼‰ã€ç»ç’ƒã€å¯†å°æ¡ã€é˜²æ¸—æ¼ã€çª—æŠŠæ‰‹ã€çª—å°æ–½å·¥ä¸é˜²æŠ¤ã€‚
- å«ç”Ÿæ´å…·ï¼šå¤–è§‚/å®‰è£…ã€é¾™å¤´/é˜€é—¨/è§’é˜€ã€å°äº”é‡‘ã€å°ç›†ä¸‹æ°´ç®¡ã€å¯†å°ã€æ·‹æµ´æˆ¿ï¼ˆè¡¨è§‚/å®‰è£…/æŒ¡æ°´æ¡ä¸æ‰“èƒ¶/å¯†å°æ€§/ç»™æ’æ°´ç³»ç»Ÿï¼‰ã€åœ°æ¼æ’æ°´ã€‚
- ç”µæ°”å®‰è£…ï¼šå¼ºç”µç®±å¤–è§‚ä¸å›è·¯å®‰è£…ã€å¼€å…³é¢æ¿è´¨é‡ä¸é«˜åº¦ã€æ’åº§å®‰è£…ä¸æ ‡è¯†ã€ç¯å…·/ç­’ç¯å®‰è£…ä¸å›è·¯æ ‡è¯†ã€è®¾å¤‡å®Œæ•´æ€§ã€‚
- ç”µå™¨è®¾å¤‡ï¼šå†…å¤–æœºã€å°å®¶ç”µã€è®¾å¤‡è¿è¡Œæƒ…å†µã€‚
- ç®¡çº¿å®‰è£…ï¼šæ–°é£ç®¡é“ã€åŠé¡¶å†…ç®¡çº¿è·¯ä¸é˜²æ°´ã€ä¸­å¤®ç©ºè°ƒå†…æœºã€å†·åª’ç®¡ã€ç»™æ’æ°´ã€‚
- æ°´æš–åŠŸèƒ½ï¼šæ´å…·/æ°´æ§½ç³»ç»Ÿã€åœ°æ¼ä¸åœ°é¢æ³›æ°´å¡åº¦ã€‚

ã€å…¬å…±éƒ¨ä½æ£€æŸ¥è¦ç‚¹ã€‘
- åœ°ä¸‹å®¤/åº•å±‚è½¦åº“ï¼šåœ°é¢ä¸å¢™é¢/é¡¶æ£šæ¶‚é¥°ã€ç®¡é“å®‰è£…ã€é˜²æ¸—æ¼ç»†éƒ¨ï¼ˆåº•æ¿/å¤–å¢™/é¡¶æ¿/ç©¿å¢™ç®¡ç­‰ï¼‰ã€é€šé£ä¸æ’é£/æ’çƒŸã€æ”¯æ¶ã€æ§åˆ¶å™¨ä¸é˜€é—¨ã€å–·å¤´ã€‚
- æ¥¼ï¼ˆç”µï¼‰æ¢¯é€šé“ä¸èµ°å»Šï¼šåœ°é¢ä¸å¢™é¢é¥°é¢ã€æ¥¼æ¢¯è¸æ­¥/å¹³å°å°ºå¯¸ã€ç–æ•£å¤–é—¨ä¸é€šé“å°ºå¯¸ã€æ æ†/æ‰¶æ‰‹å°ºå¯¸ä¸è¡¨é¢è´¨é‡ã€ç”µæ¢¯è¿è¡Œã€‚
- å¤–ç«‹é¢ï¼šæŠ¹ç°ä¸æ¶‚é¥°è¡¨è§‚ã€å¹•å¢™å®‰è£…ä¸æ¿ç¼æ³¨èƒ¶ã€é›¨æ£šæ ¹éƒ¨é˜²æ°´ä¸æ’æ°´å¡åº¦/ç®¡è®¾ç½®ã€‚
- å±‹é¢ï¼šé˜²æ°´å·æã€ç»†éƒ¨æ„é€ ã€æ’æ±½æ„é€ ã€åˆ†æ ¼ç¼ä¸æ³¨èƒ¶ã€é—¨çª—æ¡†ç¼æ³¨èƒ¶ã€æ’æ°”ç®¡/çƒŸé£å¸½ã€é›¨æ°´ç®¡/é›¨æ°´æ–—ã€æ æ†é«˜åº¦ä¸é—´è·ã€å¥³å„¿å¢™å¡åº¦ã€‚
- æˆ·å¤–å®‰è£…ï¼šé…ç”µç®±é…çº¿/æ¼ä¿/æ¥åœ°ã€é¿é›·é’ˆ/é¿é›·å¸¦ã€å®¤å¤–ç”µæ°”ï¼›æ’æ°´ç®¡é“æ¥å£ã€ç®¡é“ä¿æ¸©ã€ç»™æ°´è®¾å¤‡å™ªå£°ã€‚
- å®¤å¤–ç»¿åŒ–åŠæ— éšœç¢ï¼šåœŸæ–¹å›å¡«ã€é“è·¯ä¸é€šé“é¢å±‚ã€è·¯ç¼˜çŸ³ã€éš”ç¦»æ …ï¼›æ— éšœç¢å‡ºå…¥å£/å…¥å£å¹³å°/å…¬å…±èµ°é“/å€™æ¢¯å…ã€‚

ã€æ”¿ç­–æ–‡ä»¶ã€‘
- ã€Šä¸Šæµ·å¸‚æ¨è¿›ä½å®…å·¥ç¨‹è´¨é‡æ½œåœ¨ç¼ºé™·ä¿é™©å®æ–½åŠæ³•ã€‹ã€”2024ã€•4 å·ï¼›
- ã€Šä¸Šæµ·å¸‚ä½å®…å·¥ç¨‹è´¨é‡æ½œåœ¨ç¼ºé™·ä¿é™©å®æ–½ç»†åˆ™ã€‹ã€”2025ã€•2 å·ï¼›
- ã€Šä¸Šæµ·å¸‚å»ºè®¾å·¥ç¨‹è´¨é‡é£é™©ç®¡ç†æœºæ„ç®¡ç†è§„å®šã€‹ã€”2023ã€•12 å·ï¼›
- ã€Šä¸Šæµ·å¸‚å»ºè®¾å·¥ç¨‹è´¨é‡é£é™©ç®¡ç†æœºæ„ç®¡ç†å¯¼åˆ™ã€‹IDI-TIS-SH-2024-03ï¼›
- ã€Šä¸Šæµ·å¸‚ä½å®…å·¥ç¨‹è´¨é‡åˆ†æˆ·éªŒæ”¶ç®¡ç†åŠæ³•ã€‹ã€”2024ã€•7 å·ã€‚

ã€è§„èŒƒæ ‡å‡†ï¼ˆæŒ‰é¡¹ç›®ç‰¹ç‚¹å–èˆå¢å‡ï¼‰ã€‘
- ã€Šå»ºç­‘å·¥ç¨‹æ–½å·¥è´¨é‡éªŒæ”¶ç»Ÿä¸€æ ‡å‡†ã€‹GB50300
- ã€Šä½å®…è®¾è®¡è§„èŒƒã€‹GB50096
- ã€Šæ°‘ç”¨å»ºç­‘è®¾è®¡ç»Ÿä¸€æ ‡å‡†ã€‹GB50352
- ã€Šä½å®…è®¾è®¡æ ‡å‡†ã€‹DGJ08-20
- ã€Šå»ºç­‘æŠ—éœ‡è®¾è®¡è§„èŒƒã€‹GB50011
- ã€Šæ°‘ç”¨å»ºç­‘ä¾›æš–é€šé£ä¸ç©ºæ°”è°ƒèŠ‚è®¾è®¡è§„èŒƒã€‹GB50736
- ã€Šæ··å‡åœŸç»“æ„å·¥ç¨‹æ–½å·¥è´¨é‡éªŒæ”¶è§„èŒƒã€‹GB50204
- ã€Šåœ°ä¸‹é˜²æ°´å·¥ç¨‹è´¨é‡éªŒæ”¶è§„èŒƒã€‹GB50208
- ã€Šä½å®…å®¤å†…é˜²æ°´å·¥ç¨‹æŠ€æœ¯è§„èŒƒã€‹JGJ298
- ã€Šå»ºç­‘å¤–å¢™é˜²æ°´å·¥ç¨‹æŠ€æœ¯è§„ç¨‹ã€‹JGJ/T 235
- ã€Šå¤–å¢™å¤–ä¿æ¸©å·¥ç¨‹æŠ€æœ¯è§„ç¨‹ã€‹JGJ144
- ã€Šé“åˆé‡‘é—¨çª—å·¥ç¨‹æŠ€æœ¯è§„èŒƒã€‹JGJ214
- ã€Šé‡‘å±ä¸çŸ³æå¹•å¢™å·¥ç¨‹æŠ€æœ¯è§„èŒƒã€‹JGJ133
- ã€Šå±‹é¢å·¥ç¨‹è´¨é‡éªŒæ”¶è§„èŒƒã€‹GB50207
- ã€Šå±‹é¢å·¥ç¨‹æŠ€æœ¯è§„èŒƒã€‹GB50345
- ã€Šå»ºç­‘è£…é¥°è£…ä¿®å·¥ç¨‹è´¨é‡éªŒæ”¶æ ‡å‡†ã€‹GB50210
- ã€Šå»ºç­‘ç”µæ°”å·¥ç¨‹æ–½å·¥è´¨é‡éªŒæ”¶è§„èŒƒã€‹GB50303
- ã€Šæ™ºèƒ½å»ºç­‘å·¥ç¨‹è´¨é‡éªŒæ”¶è§„èŒƒã€‹GB50339
- ã€Šé€šé£ä¸ç©ºè°ƒå·¥ç¨‹æ–½å·¥è´¨é‡éªŒæ”¶è§„èŒƒã€‹GB50243
- ã€Šå»ºç­‘ç»™æ°´æ’æ°´åŠé‡‡æš–å·¥ç¨‹æ–½å·¥è´¨é‡éªŒæ”¶è§„èŒƒã€‹GB50242
- ã€Šå»ºç­‘èŠ‚èƒ½å·¥ç¨‹æ–½å·¥è´¨é‡éªŒæ”¶æ ‡å‡†ã€‹GB50411

ã€ä¸ä¿é™©æ ‡çš„èŒƒå›´ç›¸å…³çš„ç¼ºé™·å…³æ³¨é‡ç‚¹ï¼ˆç”¨äºé£é™©è®¤å®šæç¤ºï¼‰ã€‘
- 10 å¹´æœŸï¼šæ•´ä½“/å±€éƒ¨å€’å¡Œï¼›åœ°åŸºä¸å‡åŒ€æ²‰é™è¶…é™ï¼›æ‚¬æŒ‘æ„ä»¶ä¸å¤–å¢™ç»“æ„æ„ä»¶åå¡Œ/è„±è½/å½±å“ä½¿ç”¨å®‰å…¨è£‚ç¼ï¼›ä¸»ä½“æ‰¿é‡ç»“æ„å½±å“ç»“æ„å®‰å…¨çš„å˜å½¢/è£‚ç¼/ç ´æŸ/æ–­è£‚ï¼›æ³•å¾‹æ³•è§„å¼ºåˆ¶æ€§æ ‡å‡†è§„å®šçš„å…¶ä»–æƒ…å½¢ã€‚
- 5 å¹´æœŸï¼šå›´æŠ¤ç»“æ„ä¿æ¸©å·¥ç¨‹ï¼›åœ°ä¸‹/å±‹é¢/å¤–å¢™/å®¤å†…é˜²æ°´å·¥ç¨‹ã€‚
- 2 å¹´æœŸï¼šè£…é¥°è£…ä¿®å·¥ç¨‹ï¼ˆå«å¤–å¢™é¥°é¢ã€å®¤å†…äºŒæ¬¡ç»“æ„ã€å…¨/éå…¨è£…ä¿®ï¼‰ï¼›ç”µæ°”ç®¡çº¿/ç»™æ’æ°´ç®¡é“ä¸è®¾å¤‡å®‰è£…å·¥ç¨‹ï¼›ä¾›çƒ­ä¸ä¾›å†·ç³»ç»Ÿå®‰è£…å·¥ç¨‹ã€‚

ã€é£é™©ç­‰çº§å®šä¹‰ï¼ˆTISç¼–ç ï¼Œè¾“å‡ºæ—¶è¯·ä½¿ç”¨ä»£ç ä¸ä¸­æ–‡åï¼‰ã€‘
- A â€” æ­£å¸¸æŠ€æœ¯é£é™©ï¼ˆcolor: blueï¼‰
  - æè¿°ï¼šé£é™©ç­‰çº§ä½ï¼›æ— å½±å“ç»“æ„/ä½¿ç”¨å®‰å…¨çš„è´¨é‡ç¼ºé™·ï¼›å¯èƒ½æœ‰è½»å¾®ä½¿ç”¨åŠŸèƒ½å½±å“ï¼Œå‘ç”Ÿæ¦‚ç‡æä½ï¼›åŸºæœ¬ä¸é€ æˆæˆ–ä»…å°‘é‡è´¢äº§æŸå¤±ã€‚
  - è¦æ±‚ï¼šä¸€èˆ¬é£é™©æé†’ã€‚
- B â€” è½»å¾®æŠ€æœ¯é£é™©ï¼ˆcolor: yellowï¼‰
  - æè¿°ï¼šé£é™©ç­‰çº§è¾ƒä½ï¼›æ— å½±å“ç»“æ„å®‰å…¨ï¼›å¯¹ä½¿ç”¨å®‰å…¨/åŠŸèƒ½æœ‰è½»å¾®å½±å“ï¼›å‘ç”Ÿæ¦‚ç‡ä½ï¼›å¯èƒ½é€ æˆè½»å¾®è´¢äº§æŸå¤±ã€‚
  - è¦æ±‚ï¼šé£é™©æç¤ºï¼›éœ€å¼•èµ·æ³¨æ„ï¼Œé˜²æ­¢åŒç±»é—®é¢˜åå¤å‡ºç°ï¼Œå¹¶æ•´æ”¹ã€å›å¤TISæœºæ„ã€‚
- C â€” ä¸­ç­‰æŠ€æœ¯é£é™©ï¼ˆcolor: orangeï¼‰
  - æè¿°ï¼šé£é™©ç­‰çº§ä¸­ç­‰ï¼›å¯¹ç»“æ„å®‰å…¨æœ‰è½»å¾®å½±å“ï¼Œæˆ–å¯¹ä½¿ç”¨å®‰å…¨/åŠŸèƒ½å½±å“ä¸­ç­‰ï¼›å‘ç”Ÿæ¦‚ç‡ä½æˆ–è¾ƒé«˜ï¼›å¯é€ æˆä¸€å®šè´¢äº§æŸå¤±ã€‚
  - è¦æ±‚ï¼šé£é™©è­¦ç¤ºï¼›éœ€è½å®å¹¶é‡‡å–æªæ–½ã€æ•´æ”¹ã€å›å¤TISæœºæ„ã€‚
- D â€” ä¸¥é‡æŠ€æœ¯é£é™©ï¼ˆcolor: redï¼‰
  - æè¿°ï¼šé£é™©ç­‰çº§è¾ƒé«˜ï¼›å½±å“ç»“æ„/ä½¿ç”¨å®‰å…¨ï¼Œæˆ–äº‹æ•…æ¦‚ç‡é«˜ï¼Œä¸¥é‡å½±å“ä½¿ç”¨åŠŸèƒ½ï¼›å¯èƒ½é€ æˆä¸¥é‡è´¢äº§æŸå¤±æˆ–æ¶åŠ£ç¤¾ä¼šå½±å“ã€‚
  - è¦æ±‚ï¼šä¸¥é‡é£é™©è­¦ç¤ºï¼›è½å®å¹¶ç«‹å³é‡‡å–æ•´æ”¹ï¼Œå›å¤TISæœºæ„ã€‚
- E â€” ä¸¥é‡è´¨é‡è¡Œä¸ºé£é™©ï¼ˆcolor: redï¼‰
  - æè¿°ï¼šé£é™©ç­‰çº§è¾ƒé«˜ï¼›è¿åæ”¿åºœè´¨é‡ç®¡ç†è§„å®š/è§„èŒƒæ€§æ–‡ä»¶ï¼Œæœªå±¥è¡Œæ³•å®šç¨‹åºæˆ–æœªè½å®è´¨é‡ç®¡ç†æªæ–½ï¼Œå¯èƒ½é€ æˆè¾ƒå¤§ç¤¾ä¼šå½±å“çš„è¡Œä¸ºã€‚
  - è¦æ±‚ï¼šä¸¥é‡é£é™©è­¦ç¤ºï¼›è½å®å¹¶ç«‹å³é‡‡å–æ•´æ”¹ï¼Œå›å¤TISæœºæ„ã€‚
- R â€” æŠ€æœ¯é£é™©ä¿ç•™ï¼ˆcolor: grayï¼‰
  - æè¿°ï¼šæ£€æŸ¥ä¸­æœªèƒ½æŸ¥è§å¿…è¦å·¥åºã€ææ–™æˆ–æ§åˆ¶èµ„æ–™ä»¥è¯æ˜å…¶æ— æŠ€æœ¯é£é™©ï¼›éœ€è¿›ä¸€æ­¥èµ„æ–™ç¡®è®¤å®é™…é£é™©ç­‰çº§ã€‚
  - è¦æ±‚ï¼šæŒç»­æ”¶é›†ï¼ˆææ–™ä¸è¯æ®ï¼‰å¹¶å¤æ ¸ã€‚
- O â€” è§‚å¯Ÿé¡¹ï¼ˆcolor: greenï¼‰
  - æè¿°ï¼šè¶…å‡ºæœ¬è¡Œä¸šæŠ€æœ¯çŸ¥è¯†é¢†åŸŸæˆ–è¶…è¿‡å›½å®¶/é¡¹ç›®åœ°æ ‡å‡†è§„èŒƒè¦æ±‚ï¼Œä½†åŸºäºTISç»éªŒå­˜åœ¨ç‰©è´¨æŸåé£é™©ã€‚
  - è¦æ±‚ï¼šæŒç»­å…³æ³¨ä¸å¤æŸ¥ã€‚'''

    format_template = (
        "è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼å›ç­”ï¼š\n"
        "ã€ç¼ºé™·ã€‘ï¼š\n"
        "ã€é£é™©ã€‘ï¼š\n"
        "ã€é£é™©ç­‰çº§ï¼ˆåŸæœ¬ï¼‰ã€‘ï¼š\n"
        "ã€é£é™©ç­‰çº§ï¼ˆç°åœ¨ï¼‰ã€‘ï¼š\n"
        "ã€çº æ­£å’Œé¢„é˜²å»ºè®®ã€‘ï¼š\n"
    )
    
    if image_count > 0:
        user_text = (
            f"{base_instruction}\n"
            f"æœ¬æ¬¡åˆ†ææä¾›äº†{image_count}å¼ å›¾åƒã€‚"
            f"æ ¹æ®æä¾›çš„{image_count}å¼ å›¾åƒï¼Œè¯·åˆ†æå¯¹åº”çš„\"ç¼ºé™·\"ã€\"é£é™©\"ã€"
            f"\"é£é™©ç­‰çº§ï¼ˆåŸæœ¬ï¼‰\"å’Œ\"é£é™©ç­‰çº§ï¼ˆç°åœ¨ï¼‰\"ï¼Œå¹¶æä¾›\"çº æ­£å’Œé¢„é˜²å»ºè®®\"ã€‚\n"
            f"{format_template}"
        )
    else:
        user_text = (
            f"{base_instruction}\n"
            f"æœ¬æ¬¡åˆ†ææ²¡æœ‰æä¾›å›¾åƒï¼ˆç©ºç™½å›¾åƒä½œä¸ºå ä½å›¾ç‰‡ï¼Œè¯·å¿½ç•¥ï¼‰ï¼Œ"
            f"ä½†æ˜¯å·²çŸ¥\"ç¼ºé™·\"æ˜¯ï¼š{defect_description}ã€‚"
            f"æ ¹æ®æä¾›çš„\"ç¼ºé™·\"æ–‡æœ¬ï¼Œè¯·åˆ†æå¯¹åº”çš„\"ç¼ºé™·\"ã€\"é£é™©\"ã€"
            f"\"é£é™©ç­‰çº§ï¼ˆåŸæœ¬ï¼‰\"å’Œ\"é£é™©ç­‰çº§ï¼ˆç°åœ¨ï¼‰\"ï¼Œå¹¶æä¾›\"çº æ­£å’Œé¢„é˜²å»ºè®®\"ã€‚\n"
            f"{format_template}"
        )
    
    # 4. æ„å»ºç”¨æˆ·æ¶ˆæ¯å†…å®¹
    user_content = [{'index': None, 'text': user_text, 'type': 'text'}]
    
    # æ·»åŠ å›¾åƒå¼•ç”¨
    for i in range(len(images)):
        user_content.append({'index': i, 'text': None, 'type': 'image'})
    
    # 5. æ„å»ºåŠ©æ‰‹å›ç­”
    assistant_text = (
        f"ã€ç¼ºé™·ã€‘ï¼š{defect_description}\n"
        f"ã€é£é™©ã€‘ï¼š{risk_detail}\n"
        f"ã€é£é™©ç­‰çº§ï¼ˆåŸæœ¬ï¼‰ã€‘ï¼š{risk_level_original}\n"
        f"ã€é£é™©ç­‰çº§ï¼ˆç°åœ¨ï¼‰ã€‘ï¼š{risk_level_current}\n"
        f"ã€çº æ­£å’Œé¢„é˜²å»ºè®®ã€‘ï¼š{correction_suggestion}"
    )
    
    assistant_content = [{'index': None, 'text': assistant_text, 'type': 'text'}]
    
    # 6. æ„å»ºå®Œæ•´çš„å¯¹è¯
    messages = [
        {'content': user_content, 'role': 'user'},
        {'content': assistant_content, 'role': 'assistant'}
    ]
    
    result = {
        'messages': messages,
        'images': images
    }
    
    # æ¸…ç†å±€éƒ¨å˜é‡ä»¥é‡Šæ”¾å†…å­˜
    del messages, images, user_content, assistant_content
    return result
    

def get_images_from_paths(all_image_paths: str, dataset_path: str) -> List[Image.Image]:
    """
    æ ¹æ®å›¾ç‰‡è·¯å¾„å­—ç¬¦ä¸²åŠ è½½å›¾åƒæ–‡ä»¶ã€‚
    
    å¤„ç†JSONæ ¼å¼çš„å›¾ç‰‡è·¯å¾„æ•°ç»„ï¼Œæ”¯æŒç›¸å¯¹è·¯å¾„å’Œç»å¯¹è·¯å¾„ã€‚
    å¦‚æœæ²¡æœ‰å›¾ç‰‡è·¯å¾„ï¼Œä¼šåˆ›å»ºå ä½å›¾ç‰‡ä»¥ä¿æŒè¾“å…¥æ ¼å¼ä¸€è‡´æ€§ã€‚
    
    Args:
        all_image_paths (str): JSONæ ¼å¼çš„å›¾ç‰‡è·¯å¾„æ•°ç»„å­—ç¬¦ä¸²
            ä¾‹å¦‚: '["images/img1.jpg", "images/img2.jpg"]'
        dataset_path (str): æ•°æ®é›†æ ¹è·¯å¾„ï¼Œç”¨äºè§£æç›¸å¯¹è·¯å¾„
        
    Returns:
        List[Image.Image]: PILå›¾åƒå¯¹è±¡åˆ—è¡¨
        
    Note:
        - å›¾åƒä¼šè¢«è‡ªåŠ¨è½¬æ¢ä¸ºRGBæ ¼å¼
        - ä¸ºäº†èŠ‚çœæ˜¾å­˜ï¼Œå›¾åƒå°ºå¯¸ä¼šè¢«é™åˆ¶ä¸ºæœ€å¤§1024px
        - å¦‚æœæ²¡æœ‰å›¾ç‰‡ï¼Œä¼šåˆ›å»º224x224çš„ç™½è‰²å ä½å›¾ç‰‡
        
    Raises:
        json.JSONDecodeError: å½“å›¾ç‰‡è·¯å¾„ä¸æ˜¯æœ‰æ•ˆJSONæ ¼å¼æ—¶
        FileNotFoundError: å½“å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨æ—¶
    """
    images = []
    
    try:
        image_paths = json.loads(all_image_paths)
    except json.JSONDecodeError:
        logging.warning(f"æ— æ³•è§£æå›¾ç‰‡è·¯å¾„JSON: {all_image_paths}")
        image_paths = []
    
    # ç¡®å®šåŸºç¡€è·¯å¾„
    base_path = Path(dataset_path).parent if dataset_path.endswith('.csv') else Path(dataset_path)
    
    # åŠ è½½æ¯å¼ å›¾ç‰‡
    for image_path in image_paths:
        try:
            full_img_path = base_path / image_path
            
            # ä½¿ç”¨withè¯­å¥ç¡®ä¿å›¾åƒæ–‡ä»¶å¥æŸ„è¢«æ­£ç¡®å…³é—­
            with Image.open(full_img_path) as img:
                # åˆ›å»ºå‰¯æœ¬å¹¶è½¬æ¢ä¸ºRGBæ ¼å¼ï¼Œé¿å…æ‡’åŠ è½½é—®é¢˜
                image = img.convert("RGB").copy()
                
                # é™åˆ¶å›¾åƒæœ€å¤§å°ºå¯¸ä»¥å‡å°‘æ˜¾å­˜å ç”¨
                max_size = 1024
                if max(image.size) > max_size:
                    image.thumbnail((max_size, max_size), Image.Resampling.LANCZOS)
                    
                images.append(image)
                
        except FileNotFoundError:
            logging.error(f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {full_img_path}")
            continue
        except Exception as e:
            logging.error(f"åŠ è½½å›¾ç‰‡æ—¶å‡ºé”™ {image_path}: {e}")
            continue
    
    # å¦‚æœæ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•å›¾ç‰‡ï¼Œåˆ›å»ºå ä½å›¾ç‰‡
    if not images:
        placeholder = Image.new('RGB', (224, 224), color='white') # ä½¿ç”¨æ ‡å‡†å°ºå¯¸çš„ç™½è‰²å ä½å›¾ç‰‡
        images.append(placeholder)
        # logging.info("ä½¿ç”¨ç™½è‰²å ä½å›¾ç‰‡")
    
    return images


# =============================================================================
# æ•°æ®æ•´ç†å™¨ (Data Collator)
# =============================================================================

def collate_fn(examples: List[Dict[str, Any]]) -> Dict[str, torch.Tensor]:
    """
    æ•°æ®æ•´ç†å‡½æ•°ï¼Œå°†æ‰¹æ¬¡æ ·æœ¬è½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥æ ¼å¼ã€‚
    
    æ­¤å‡½æ•°æ˜¯è®­ç»ƒæµç¨‹çš„å…³é”®ç»„ä»¶ï¼Œè´Ÿè´£ï¼š
    1. åº”ç”¨å¯¹è¯æ¨¡æ¿å¹¶åˆ†è¯åŒ–æ–‡æœ¬
    2. å¤„ç†å›¾åƒæ•°æ®
    3. åˆ›å»ºè®­ç»ƒæ ‡ç­¾å¹¶é®è”½ç‰¹æ®Štoken
    4. å†…å­˜ç®¡ç†å’Œæ˜¾å­˜æ¸…ç†
    
    Args:
        examples (List[Dict[str, Any]]): æ‰¹æ¬¡æ ·æœ¬åˆ—è¡¨ï¼Œæ¯ä¸ªæ ·æœ¬åŒ…å«messageså’Œimages
        
    Returns:
        Dict[str, torch.Tensor]: æ¨¡å‹è®­ç»ƒæ‰€éœ€çš„æ‰¹æ¬¡æ•°æ®ï¼ŒåŒ…å«ï¼š
            - input_ids: åˆ†è¯åçš„è¾“å…¥åºåˆ—
            - attention_mask: æ³¨æ„åŠ›æ©ç 
            - pixel_values: å›¾åƒåƒç´ å€¼
            - labels: è®­ç»ƒæ ‡ç­¾ï¼ˆé®è”½äº†paddingå’Œå›¾åƒtokenï¼‰
            
    Note:
        - ä¼šè‡ªåŠ¨é®è”½padding tokenå’Œå›¾åƒtokençš„æŸå¤±è®¡ç®—
        - æ”¯æŒå¯é€‰çš„å‘¨æœŸæ€§å†…å­˜æ¸…ç†åŠŸèƒ½
        - åœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­åªåœ¨rank 0æ‰“å°è°ƒè¯•ä¿¡æ¯
    """
    # 1. åº”ç”¨å¯¹è¯æ¨¡æ¿å¹¶æå–æ–‡æœ¬å’Œå›¾åƒ
    texts = [processor.apply_chat_template(example["messages"], tokenize=False) 
             for example in examples]
    images = [example["images"] for example in examples]

    # 2. åˆ†è¯åŒ–æ–‡æœ¬å¹¶å¤„ç†å›¾åƒ
    batch = processor(text=texts, images=images, return_tensors="pt", padding=True)

    # 3. åˆ›å»ºè®­ç»ƒæ ‡ç­¾
    labels = batch["input_ids"].clone()
    
    # é®è”½padding tokenï¼Œä¸å‚ä¸æŸå¤±è®¡ç®—
    labels[labels == processor.tokenizer.pad_token_id] = -100
    
    # é®è”½å›¾åƒtokenï¼Œä¸å‚ä¸æŸå¤±è®¡ç®—ï¼ˆæ¨¡å‹ç‰¹å®šï¼‰
    image_token_id = processor.tokenizer.convert_tokens_to_ids(processor.image_token)
    labels[labels == image_token_id] = -100
    
    batch["labels"] = labels
    
    # 4. æ¸…ç†ä¸­é—´å˜é‡ï¼Œé‡Šæ”¾å†…å­˜
    del texts, images, labels

    # 5. å¯é€‰çš„å‘¨æœŸæ€§å†…å­˜æ¸…ç†
    _perform_optional_cleanup(examples)

    return batch


def _perform_optional_cleanup(examples: List[Dict[str, Any]]) -> None:
    """
    æ‰§è¡Œå¯é€‰çš„å‘¨æœŸæ€§å†…å­˜æ¸…ç†ã€‚
    
    é€šè¿‡ç¯å¢ƒå˜é‡CLEANUP_EVERY_Næ§åˆ¶æ¸…ç†é¢‘ç‡ï¼Œä»…åœ¨ä¸»è¿›ç¨‹ä¸­æ‰§è¡Œï¼Œ
    é¿å…åœ¨DataLoader workerè¿›ç¨‹ä¸­è¿›è¡ŒCUDAæ¸…ç†å¯¼è‡´çš„é—®é¢˜ã€‚
    
    Args:
        examples (List[Dict[str, Any]]): å½“å‰æ‰¹æ¬¡çš„æ ·æœ¬ï¼Œç”¨äºè°ƒè¯•è¾“å‡º
        
    Note:
        - ä»…åœ¨CLEANUP_EVERY_N > 0æ—¶å¯ç”¨
        - åªåœ¨ä¸»è¿›ç¨‹ä¸­æ‰§è¡Œï¼ˆworker_info is Noneï¼‰
        - åªåœ¨rank 0è¿›ç¨‹ä¸­æ‰“å°è°ƒè¯•ä¿¡æ¯
    """
    try:
        from torch.utils.data import get_worker_info
        worker_info = get_worker_info()
    except Exception:
        worker_info = None

    # åªåœ¨ä¸»è¿›ç¨‹ä¸­æ‰§è¡Œæ¸…ç†ï¼Œä½†æ˜¯æ¯ä¸ªGPUè¿›ç¨‹éƒ½ä¼šæ‰§è¡Œè‡ªå·±çš„æ¸…ç†
    if worker_info is None:
        global _collate_batch_count
        _collate_batch_count += 1
        
        if CLEANUP_EVERY_N > 0 and (_collate_batch_count % CLEANUP_EVERY_N == 0):
            # è·å–è¿›ç¨‹rankä¿¡æ¯
            try:
                import torch.distributed as dist
                rank = dist.get_rank() if dist.is_initialized() else int(os.getenv("RANK", "0"))
            except Exception:
                rank = int(os.getenv("RANK", "0"))
            
            device_str = f"cuda:{torch.cuda.current_device()}" if torch.cuda.is_available() else "cpu"

            # åªåœ¨rank 0æ‰“å°è°ƒè¯•ä¿¡æ¯
            if rank == 0:
                logging.info(f"\n[rank={rank} device={device_str}] ğŸ” æ¸…ç†å‰æ˜¾å­˜çŠ¶æ€ï¼š")
                os.system("nvidia-smi --query-gpu=index,name,utilization.gpu,memory.used,memory.total "
                         "--format=csv,noheader,nounits")
                logging.info(f"[rank={rank} device={device_str}] ğŸ” æ¸…ç†å†…å­˜: {_collate_batch_count} ä¸ª batch")
                logging.info(f"[rank={rank} device={device_str}] ç¬¬ä¸€ä¸ªæ ·æœ¬: {examples[0]}")

            # æ‰§è¡Œå†…å­˜å’Œæ˜¾å­˜æ¸…ç†
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

            if rank == 0:
                logging.info(f"[rank={rank} device={device_str}] ğŸ” æ¸…ç†åæ˜¾å­˜çŠ¶æ€ï¼š")
                os.system("nvidia-smi --query-gpu=index,name,utilization.gpu,memory.used,memory.total "
                         "--format=csv,noheader,nounits")


# =============================================================================
# å…¨å±€å˜é‡å’Œé…ç½®
# =============================================================================

# å‘¨æœŸæ€§å†…å­˜æ¸…ç†é…ç½®ï¼ˆé€šè¿‡ç¯å¢ƒå˜é‡æ§åˆ¶ï¼‰
CLEANUP_EVERY_N = int(os.getenv("CLEANUP_EVERY_N", "0"))
_collate_batch_count = 0  # ä»…åœ¨ä¸»è¿›ç¨‹ä¸­é€’å¢

# å…¨å±€å¤„ç†å™¨å˜é‡ï¼ˆåœ¨ä¸»å‡½æ•°ä¸­åˆå§‹åŒ–ï¼‰
processor: Optional[AutoProcessor] = None


# =============================================================================
# ä¸»è®­ç»ƒæµç¨‹
# =============================================================================

def main() -> None:
    """
    ä¸»è®­ç»ƒå‡½æ•°ã€‚
    
    æ‰§è¡Œå®Œæ•´çš„æ¨¡å‹è®­ç»ƒæµç¨‹ï¼ŒåŒ…æ‹¬ï¼š
    1. è§£æå‘½ä»¤è¡Œå‚æ•°å’Œé…ç½®
    2. åˆå§‹åŒ–æ¨¡å‹ã€å¤„ç†å™¨å’Œåˆ†è¯å™¨
    3. åŠ è½½å’Œé¢„å¤„ç†æ•°æ®é›†
    4. é…ç½®å’Œå¯åŠ¨è®­ç»ƒ
    5. ä¿å­˜æ¨¡å‹å’Œæ¨é€åˆ°Hub
    """
    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = TrlParser((ScriptArguments, SFTConfig, ModelConfig))
    script_args, training_args, model_args = parser.parse_args_and_config()
    
    # é…ç½®è®­ç»ƒå‚æ•°
    training_args.gradient_checkpointing_kwargs = dict(use_reentrant=False)
    training_args.remove_unused_columns = False
    training_args.dataset_kwargs = {"skip_prepare_dataset": True}
    
    logging.info("å¼€å§‹åˆå§‹åŒ–æ¨¡å‹å’Œå¤„ç†å™¨...")
    
    # åˆå§‹åŒ–æ¨¡å‹ã€åˆ†è¯å™¨å’Œå¤„ç†å™¨
    global processor
    processor, model = _initialize_model_and_processor(model_args)
    
    logging.info("å¼€å§‹åŠ è½½å’Œé¢„å¤„ç†æ•°æ®é›†...")

    # åªåœ¨ä¸»è¿›ç¨‹ä¸­è®¡ç®—æ•°æ®é¢„å¤„ç†ï¼Œæé«˜æ•ˆç‡
    # å‚è€ƒ: https://github.com/huggingface/trl/pull/1255
    state = PartialState()
    with state.local_main_process_first():
        # åŠ è½½å’Œé¢„å¤„ç†æ•°æ®é›†
        dataset = _load_and_prepare_dataset(script_args)
    
    logging.info("å¼€å§‹é…ç½®è®­ç»ƒå™¨...")
    
    # è®­ç»ƒå‰å†…å­˜æ¸…ç†
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    
    # é…ç½®è®­ç»ƒå™¨
    trainer = SFTTrainer(
        model=model,
        args=training_args,
        data_collator=collate_fn,
        train_dataset=dataset[script_args.dataset_train_split],
        eval_dataset=dataset[script_args.dataset_test_split] if training_args.eval_strategy != "no" else None,
        processing_class=processor.tokenizer,
        peft_config=get_peft_config(model_args),
    )

    logging.info("å¼€å§‹è®­ç»ƒ...")
    trainer.train()

    logging.info("è®­ç»ƒå®Œæˆï¼Œä¿å­˜æ¨¡å‹...")
    _save_and_upload_model(trainer, training_args, script_args)
    
    logging.info("è®­ç»ƒæµç¨‹å…¨éƒ¨å®Œæˆï¼")


def _initialize_model_and_processor(model_args: ModelConfig) -> Tuple[AutoProcessor, PreTrainedModel]:
    """
    åˆå§‹åŒ–æ¨¡å‹å’Œå¤„ç†å™¨ã€‚
    
    Args:
        model_args (ModelConfig): æ¨¡å‹é…ç½®å‚æ•°
        
    Returns:
        Tuple[AutoProcessor, PreTrainedModel]: (processor, model) å¤„ç†å™¨å’Œæ¨¡å‹å¯¹è±¡
        
    Raises:
        ValueError: å½“æ¨¡å‹é…ç½®å‚æ•°æ— æ•ˆæ—¶
        OSError: å½“æ¨¡å‹æ–‡ä»¶æ— æ³•åŠ è½½æ—¶
    """
    # ç¡®å®šæ•°æ®ç±»å‹
    torch_dtype = (
        model_args.torch_dtype 
        if model_args.torch_dtype in ["auto", None] 
        else getattr(torch, model_args.torch_dtype)
    )
    
    # è·å–é‡åŒ–é…ç½®
    quantization_config = get_quantization_config(model_args)
    
    # æ„å»ºæ¨¡å‹å‚æ•°
    model_kwargs = dict(
        revision=model_args.model_revision,
        attn_implementation=model_args.attn_implementation,
        torch_dtype=torch_dtype,
        # æ³¨é‡Šæ‰device_mapä»¥é¿å…ä¸DeepSpeedå†²çª
        # device_map=get_kbit_device_map() if quantization_config is not None else None,
        quantization_config=quantization_config,
    )
    
    try:
        # åŠ è½½å¤„ç†å™¨
        processor = AutoProcessor.from_pretrained(
            model_args.model_name_or_path, 
            trust_remote_code=model_args.trust_remote_code
        )

        # åŠ è½½æ¨¡å‹
        model = AutoModelForImageTextToText.from_pretrained(
            model_args.model_name_or_path, 
            trust_remote_code=model_args.trust_remote_code, 
            **model_kwargs
        )
        
        logging.info(f"æˆåŠŸåŠ è½½æ¨¡å‹: {model_args.model_name_or_path}")
        return processor, model
        
    except Exception as e:
        logging.error(f"åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
        raise OSError(f"æ— æ³•åŠ è½½æ¨¡å‹ {model_args.model_name_or_path}: {e}") from e


def _load_and_prepare_dataset(script_args: ScriptArguments) -> DatasetDict:
    """
    åŠ è½½å’Œé¢„å¤„ç†æ•°æ®é›†ã€‚
    
    Args:
        script_args (ScriptArguments): è„šæœ¬å‚æ•°é…ç½®
        
    Returns:
        DatasetDict: é¢„å¤„ç†åçš„æ•°æ®é›†
        
    Raises:
        FileNotFoundError: å½“æ•°æ®é›†æ–‡ä»¶ä¸å­˜åœ¨æ—¶
        ValueError: å½“æ•°æ®é›†æ ¼å¼ä¸æ­£ç¡®æ—¶
    """
    try:
        if script_args.dataset_name.endswith('.csv'):
            # ä»CSVæ–‡ä»¶åŠ è½½æ•°æ®é›†
            if not Path(script_args.dataset_name).exists():
                raise FileNotFoundError(f"æ•°æ®é›†æ–‡ä»¶ä¸å­˜åœ¨: {script_args.dataset_name}")
            
            dataset = load_dataset('csv', data_files=script_args.dataset_name)
            dataset = prepare_dataset(
                dataset, 
                script_args.dataset_name, 
                script_args.dataset_train_split, 
                templates=None
            )
            logging.info("æˆåŠŸä»CSVæ–‡ä»¶åŠ è½½æ•°æ®é›†")
        else:
            # ä»HuggingFace HubåŠ è½½æ•°æ®é›†
            dataset = load_dataset(
                script_args.dataset_name, 
                name=script_args.dataset_config
            )
            logging.info("æˆåŠŸä»HuggingFace HubåŠ è½½æ•°æ®é›†")
    
        return dataset
        
    except Exception as e:
        logging.error(f"åŠ è½½æ•°æ®é›†å¤±è´¥: {e}")
        if isinstance(e, FileNotFoundError):
            raise
        else:
            raise ValueError(f"æ•°æ®é›†æ ¼å¼é”™è¯¯æˆ–åŠ è½½å¤±è´¥: {e}") from e


def _save_and_upload_model(
    trainer: SFTTrainer, 
    training_args: SFTConfig, 
    script_args: ScriptArguments
) -> None:
    """
    ä¿å­˜æ¨¡å‹å¹¶å¯é€‰åœ°ä¸Šä¼ åˆ°Hubã€‚
    
    Args:
        trainer (SFTTrainer): è®­ç»ƒå™¨å¯¹è±¡
        training_args (SFTConfig): è®­ç»ƒé…ç½®
        script_args (ScriptArguments): è„šæœ¬å‚æ•°
        
    Raises:
        OSError: å½“æ¨¡å‹ä¿å­˜å¤±è´¥æ—¶
        ConnectionError: å½“æ¨é€åˆ°Hubå¤±è´¥æ—¶
    """
    try:
        # ä¿å­˜æ¨¡å‹
        trainer.save_model(training_args.output_dir)
        logging.info(f"æ¨¡å‹å·²ä¿å­˜åˆ°: {training_args.output_dir}")
        
        # å¯é€‰åœ°æ¨é€åˆ°Hub
        if training_args.push_to_hub:
            try:
                trainer.push_to_hub(dataset_name=script_args.dataset_name)
                
                # åªåœ¨ä¸»è¿›ç¨‹ä¸­æ¨é€å¤„ç†å™¨
                if trainer.accelerator.is_main_process:
                    if processor is not None:
                        processor.push_to_hub(training_args.hub_model_id)
                        logging.info(f"æ¨¡å‹å’Œå¤„ç†å™¨å·²æ¨é€åˆ°Hub: {training_args.hub_model_id}")
                    else:
                        logging.warning("å¤„ç†å™¨ä¸ºNoneï¼Œæ— æ³•æ¨é€åˆ°Hub")
                        
            except Exception as e:
                logging.error(f"æ¨é€åˆ°Hubå¤±è´¥: {e}")
                raise ConnectionError(f"æ— æ³•æ¨é€æ¨¡å‹åˆ°Hub: {e}") from e
                
    except Exception as e:
        if not isinstance(e, ConnectionError):
            logging.error(f"ä¿å­˜æ¨¡å‹å¤±è´¥: {e}")
            raise OSError(f"æ— æ³•ä¿å­˜æ¨¡å‹åˆ° {training_args.output_dir}: {e}") from e
        else:
            raise


if __name__ == "__main__":
    main()
