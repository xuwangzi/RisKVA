#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
RisKVA é£é™©è¯„ä¼°æ¨¡å‹è®­ç»ƒè„šæœ¬

æœ¬è„šæœ¬ç”¨äºè®­ç»ƒåŸºäºè§†è§‰è¯­è¨€æ¨¡å‹çš„æˆ¿å±‹åˆ†æˆ·æ£€æŸ¥é£é™©è¯„ä¼°æ¨¡å‹ã€‚
æ”¯æŒå¤šæ¨¡æ€è¾“å…¥ï¼ˆå›¾åƒ+æ–‡æœ¬ï¼‰ï¼Œèƒ½å¤Ÿåˆ†æç¼ºé™·å¹¶è¯„ä¼°é£é™©ç­‰çº§ã€‚

ä¸»è¦åŠŸèƒ½ï¼š
- æ•°æ®é¢„å¤„ç†å’Œæ ¼å¼è½¬æ¢
- å¤šæ¨¡æ€æ¨¡å‹è®­ç»ƒ
- å†…å­˜ä¼˜åŒ–å’Œæ˜¾å­˜ç®¡ç†
- åˆ†å¸ƒå¼è®­ç»ƒæ”¯æŒ

ä½œè€…: RisKVA Team
åˆ›å»ºæ—¶é—´: 2024
"""

# æ ‡å‡†åº“å¯¼å…¥
import gc
import json
import logging
import os
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple, Union

# ç¬¬ä¸‰æ–¹åº“å¯¼å…¥
import torch
from accelerate import PartialState
from datasets import Dataset, DatasetDict, load_dataset  # type: ignore
from PIL import Image
from transformers import (
    AutoModelForImageTextToText, 
    AutoProcessor, 
    LlavaForConditionalGeneration,
    PreTrainedModel
)

# TRL ç›¸å…³å¯¼å…¥
from trl import (  # type: ignore
    ModelConfig,
    ScriptArguments,
    SFTConfig,
    SFTTrainer,
    TrlParser,
    get_kbit_device_map,
    get_peft_config,
    get_quantization_config,
)

# =============================================================================
# æ•°æ®é›†é¢„å¤„ç†æ¨¡å—
# =============================================================================

def prepare_dataset(
    dataset: DatasetDict, 
    dataset_path: str, 
    dataset_train_split: str, 
    templates: Optional[Dict[str, Any]] = None
) -> DatasetDict:
    """ todo 1.ä¿®æ”¹prompt 2.æ·»åŠ å›¾åƒå¢å¼ºå¤„ç†
    å‡†å¤‡è®­ç»ƒæ•°æ®é›†ï¼Œå°†åŸå§‹æ•°æ®è½¬æ¢ä¸ºæ¨¡å‹å¯ç”¨çš„æ ¼å¼ã€‚
    
    Args:
        dataset (DatasetDict): åŸå§‹æ•°æ®é›†
        dataset_path (str): æ•°æ®é›†æ–‡ä»¶è·¯å¾„ï¼Œç”¨äºå®šä½å›¾åƒæ–‡ä»¶
        dataset_train_split (str): è®­ç»ƒé›†åˆ†å‰²åç§°ï¼Œé€šå¸¸ä¸º'train'
        templates (Optional[Dict[str, Any]]): å¯é€‰çš„æ¨¡æ¿é…ç½®ï¼Œæš‚æœªä½¿ç”¨
        
    Returns:
        DatasetDict: è½¬æ¢åçš„æ•°æ®é›†ï¼ŒåŒ…å«messageså’Œimageså­—æ®µ
        
    Note:
        è½¬æ¢åçš„æ•°æ®æ ¼å¼ç¬¦åˆTRL SFTTrainerçš„è¦æ±‚ï¼š
        - messages: å¯¹è¯æ ¼å¼çš„æ–‡æœ¬æ•°æ®
        - images: PILå›¾åƒå¯¹è±¡åˆ—è¡¨
    """
    logging.info(f"å¼€å§‹å‡†å¤‡æ•°æ®é›†ï¼Œè®­ç»ƒåˆ†å‰²: {dataset_train_split}")
    
    # è½¬æ¢è®­ç»ƒé›†æ•°æ®
    train_data = transform_dataset(dataset[dataset_train_split], dataset_path)
    
    # åˆ›å»ºæ–°çš„æ•°æ®é›†å¯¹è±¡
    new_train_dataset = Dataset.from_dict(train_data)
    
    # æ„å»ºæ–°çš„DatasetDict
    new_dataset = DatasetDict({
        dataset_train_split: new_train_dataset
    })
    
    logging.info(f"æ•°æ®é›†å‡†å¤‡å®Œæˆï¼Œæ ·æœ¬æ•°é‡: {len(new_train_dataset)}")
    return new_dataset


def transform_dataset(dataset_split: DatasetDict, dataset_path: str) -> Dict[str, List[Any]]:
    """
    è½¬æ¢æ•°æ®é›†åˆ†å‰²ä¸ºæ¨¡å‹è®­ç»ƒæ ¼å¼ã€‚
    
    å°†åŸå§‹æ•°æ®é›†ä¸­çš„æ¯ä¸ªæ ·æœ¬è½¬æ¢ä¸ºåŒ…å«å¯¹è¯æ¶ˆæ¯å’Œå›¾åƒçš„æ ¼å¼ï¼Œ
    é€‚ç”¨äºå¤šæ¨¡æ€è¯­è¨€æ¨¡å‹è®­ç»ƒã€‚
    
    Args:
        dataset_split (DatasetDict): æ•°æ®é›†çš„æŸä¸ªåˆ†å‰²ï¼ˆå¦‚è®­ç»ƒé›†ï¼‰
        dataset_path (str): æ•°æ®é›†è·¯å¾„ï¼Œç”¨äºæ„å»ºå›¾åƒæ–‡ä»¶çš„å®Œæ•´è·¯å¾„
        
    Returns:
        Dict[str, List[Any]]: è½¬æ¢åçš„æ•°æ®ï¼ŒåŒ…å«ï¼š
            - messages: å¯¹è¯æ ¼å¼çš„æ¶ˆæ¯åˆ—è¡¨
            - images: å¯¹åº”çš„å›¾åƒåˆ—è¡¨
            
    Note:
        ä¸ºäº†ä¼˜åŒ–å†…å­˜ä½¿ç”¨ï¼Œå‡½æ•°ä¼šåœ¨å¤„ç†è¿‡ç¨‹ä¸­ä¸»åŠ¨æ¸…ç†ä¸­é—´å˜é‡
        å¹¶è§¦å‘åƒåœ¾å›æ”¶ã€‚
    """
    logging.info(f"å¼€å§‹è½¬æ¢æ•°æ®é›†ï¼Œæ ·æœ¬æ•°é‡: {len(dataset_split)}")
    
    transformed_data = {
        'messages': [],
        'images': []
    }
    
    for idx, sample in enumerate(dataset_split):
        try:
            formatted = format_sample(sample, dataset_path)
            transformed_data['messages'].append(formatted['messages'])
            transformed_data['images'].append(formatted['images'])
            
            # æ¸…ç†ä¸­é—´å˜é‡ï¼Œé‡Šæ”¾å†…å­˜
            del formatted
            
            # æ¯å¤„ç†1000ä¸ªæ ·æœ¬æ‰“å°ä¸€æ¬¡è¿›åº¦
            if (idx + 1) % 1000 == 0:
                logging.info(f"å·²å¤„ç†æ ·æœ¬: {idx + 1}/{len(dataset_split)}")
                
        except Exception as e:
            logging.error(f"å¤„ç†æ ·æœ¬ {idx} æ—¶å‡ºé”™: {e}")
            continue
    
    # ä¸»åŠ¨è§¦å‘åƒåœ¾å›æ”¶
    gc.collect()
    logging.info("æ•°æ®é›†è½¬æ¢å®Œæˆ")
    return transformed_data

    
def format_sample(sample: Dict[str, Any], dataset_path: str) -> Dict[str, Any]:
    """
    å°†å•ä¸ªæ•°æ®æ ·æœ¬è½¬æ¢ä¸ºæ¨¡å‹è®­ç»ƒæ‰€éœ€çš„å¯¹è¯æ ¼å¼ã€‚
    
    æ­¤å‡½æ•°æ˜¯æ•°æ®é¢„å¤„ç†çš„æ ¸å¿ƒï¼Œå°†åŸå§‹çš„æˆ¿å±‹æ£€æŸ¥æ•°æ®è½¬æ¢ä¸º
    å¤šæ¨¡æ€å¯¹è¯æ ¼å¼ï¼ŒåŒ…æ‹¬ç”¨æˆ·é—®é¢˜å’ŒåŠ©æ‰‹å›ç­”ã€‚
    
    Args:
        sample (Dict[str, Any]): åŸå§‹æ•°æ®æ ·æœ¬ï¼ŒåŒ…å«å›¾åƒè·¯å¾„å’Œæ–‡æœ¬å­—æ®µ
        dataset_path (str): æ•°æ®é›†æ ¹è·¯å¾„ï¼Œç”¨äºæ„å»ºå›¾åƒçš„å®Œæ•´è·¯å¾„
        
    Returns:
        Dict[str, Any]: æ ¼å¼åŒ–åçš„æ ·æœ¬ï¼ŒåŒ…å«ï¼š
            - messages: ç”¨æˆ·å’ŒåŠ©æ‰‹çš„å¯¹è¯æ¶ˆæ¯
            - images: PILå›¾åƒå¯¹è±¡åˆ—è¡¨
            
    Note:
        æ”¯æŒæœ‰å›¾åƒå’Œæ— å›¾åƒä¸¤ç§æƒ…å†µï¼š
        - æœ‰å›¾åƒï¼šè¦æ±‚æ¨¡å‹åŸºäºå›¾åƒè¿›è¡Œåˆ†æ
        - æ— å›¾åƒï¼šæä¾›ç¼ºé™·æ–‡æœ¬æè¿°ï¼Œè¦æ±‚åŸºäºæ–‡æœ¬åˆ†æ
    """
    # 1. åŠ è½½å›¾åƒ
    all_image_paths = sample.get('all_image_paths', '[]')
    images = get_images_from_paths(all_image_paths, dataset_path)
    
    # 2. æå–æ ·æœ¬å­—æ®µï¼Œæä¾›é»˜è®¤å€¼
    defect_description = sample.get('defect_description_text', 'æœªçŸ¥ç¼ºé™·')
    risk_detail = sample.get('risk_detail', 'é£é™©è¯¦æƒ…æœªæä¾›')
    correction_suggestion = sample.get('correction_suggestion', 'å»ºè®®æœªæä¾›')
    risk_level_original = sample.get('risk_level_original', 'é£é™©ç­‰çº§ï¼ˆåŸæœ¬ï¼‰æœªæä¾›')
    risk_level_current = sample.get('risk_level_current', 'é£é™©ç­‰çº§ï¼ˆç°åœ¨ï¼‰æœªæä¾›')
    
    # 3. æ„å»ºç”¨æˆ·é—®é¢˜
    image_count = sample.get('image_count', 0)
    base_instruction = "ä½œä¸ºæˆ¿å±‹åˆ†æˆ·æ£€æŸ¥ä¸“å®¶ï¼Œä½ ç°åœ¨æ­£åœ¨è¿›è¡Œåˆ†æˆ·æ£€æŸ¥åˆ†æã€‚"
    format_template = (
        "è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼å›ç­”ï¼š\n"
        "ã€ç¼ºé™·ã€‘ï¼š\n"
        "ã€é£é™©ã€‘ï¼š\n"
        "ã€é£é™©ç­‰çº§ï¼ˆåŸæœ¬ï¼‰ã€‘ï¼š\n"
        "ã€é£é™©ç­‰çº§ï¼ˆç°åœ¨ï¼‰ã€‘ï¼š\n"
        "ã€çº æ­£å’Œé¢„é˜²å»ºè®®ã€‘ï¼š\n"
    )
    
    if image_count > 0:
        user_text = (
            f"{base_instruction}\n"
            f"æœ¬æ¬¡åˆ†ææä¾›äº†{image_count}å¼ å›¾åƒã€‚"
            f"æ ¹æ®æä¾›çš„{image_count}å¼ å›¾åƒï¼Œè¯·åˆ†æå¯¹åº”çš„\"ç¼ºé™·\"ã€\"é£é™©\"ã€"
            f"\"é£é™©ç­‰çº§ï¼ˆåŸæœ¬ï¼‰\"å’Œ\"é£é™©ç­‰çº§ï¼ˆç°åœ¨ï¼‰\"ï¼Œå¹¶æä¾›\"çº æ­£å’Œé¢„é˜²å»ºè®®\"ã€‚\n"
            f"{format_template}"
        )
    else:
        user_text = (
            f"{base_instruction}\n"
            f"æœ¬æ¬¡åˆ†ææ²¡æœ‰æä¾›å›¾åƒï¼ˆç©ºç™½å›¾åƒä½œä¸ºå ä½å›¾ç‰‡ï¼Œè¯·å¿½ç•¥ï¼‰ï¼Œ"
            f"ä½†æ˜¯å·²çŸ¥\"ç¼ºé™·\"æ˜¯ï¼š{defect_description}ã€‚"
            f"æ ¹æ®æä¾›çš„\"ç¼ºé™·\"æ–‡æœ¬ï¼Œè¯·åˆ†æå¯¹åº”çš„\"ç¼ºé™·\"ã€\"é£é™©\"ã€"
            f"\"é£é™©ç­‰çº§ï¼ˆåŸæœ¬ï¼‰\"å’Œ\"é£é™©ç­‰çº§ï¼ˆç°åœ¨ï¼‰\"ï¼Œå¹¶æä¾›\"çº æ­£å’Œé¢„é˜²å»ºè®®\"ã€‚\n"
            f"{format_template}"
        )
    
    # 4. æ„å»ºç”¨æˆ·æ¶ˆæ¯å†…å®¹
    user_content = [{'index': None, 'text': user_text, 'type': 'text'}]
    
    # æ·»åŠ å›¾åƒå¼•ç”¨
    for i in range(len(images)):
        user_content.append({'index': i, 'text': None, 'type': 'image'})
    
    # 5. æ„å»ºåŠ©æ‰‹å›ç­”
    assistant_text = (
        f"ã€ç¼ºé™·ã€‘ï¼š{defect_description}\n"
        f"ã€é£é™©ã€‘ï¼š{risk_detail}\n"
        f"ã€é£é™©ç­‰çº§ï¼ˆåŸæœ¬ï¼‰ã€‘ï¼š{risk_level_original}\n"
        f"ã€é£é™©ç­‰çº§ï¼ˆç°åœ¨ï¼‰ã€‘ï¼š{risk_level_current}\n"
        f"ã€çº æ­£å’Œé¢„é˜²å»ºè®®ã€‘ï¼š{correction_suggestion}"
    )
    
    assistant_content = [{'index': None, 'text': assistant_text, 'type': 'text'}]
    
    # 6. æ„å»ºå®Œæ•´çš„å¯¹è¯
    messages = [
        {'content': user_content, 'role': 'user'},
        {'content': assistant_content, 'role': 'assistant'}
    ]
    
    result = {
        'messages': messages,
        'images': images
    }
    
    # æ¸…ç†å±€éƒ¨å˜é‡ä»¥é‡Šæ”¾å†…å­˜
    del messages, images, user_content, assistant_content
    return result
    

def get_images_from_paths(all_image_paths: str, dataset_path: str) -> List[Image.Image]:
    """
    æ ¹æ®å›¾ç‰‡è·¯å¾„å­—ç¬¦ä¸²åŠ è½½å›¾åƒæ–‡ä»¶ã€‚
    
    å¤„ç†JSONæ ¼å¼çš„å›¾ç‰‡è·¯å¾„æ•°ç»„ï¼Œæ”¯æŒç›¸å¯¹è·¯å¾„å’Œç»å¯¹è·¯å¾„ã€‚
    å¦‚æœæ²¡æœ‰å›¾ç‰‡è·¯å¾„ï¼Œä¼šåˆ›å»ºå ä½å›¾ç‰‡ä»¥ä¿æŒè¾“å…¥æ ¼å¼ä¸€è‡´æ€§ã€‚
    
    Args:
        all_image_paths (str): JSONæ ¼å¼çš„å›¾ç‰‡è·¯å¾„æ•°ç»„å­—ç¬¦ä¸²
            ä¾‹å¦‚: '["images/img1.jpg", "images/img2.jpg"]'
        dataset_path (str): æ•°æ®é›†æ ¹è·¯å¾„ï¼Œç”¨äºè§£æç›¸å¯¹è·¯å¾„
        
    Returns:
        List[Image.Image]: PILå›¾åƒå¯¹è±¡åˆ—è¡¨
        
    Note:
        - å›¾åƒä¼šè¢«è‡ªåŠ¨è½¬æ¢ä¸ºRGBæ ¼å¼
        - ä¸ºäº†èŠ‚çœæ˜¾å­˜ï¼Œå›¾åƒå°ºå¯¸ä¼šè¢«é™åˆ¶ä¸ºæœ€å¤§1024px
        - å¦‚æœæ²¡æœ‰å›¾ç‰‡ï¼Œä¼šåˆ›å»º224x224çš„ç™½è‰²å ä½å›¾ç‰‡
        
    Raises:
        json.JSONDecodeError: å½“å›¾ç‰‡è·¯å¾„ä¸æ˜¯æœ‰æ•ˆJSONæ ¼å¼æ—¶
        FileNotFoundError: å½“å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨æ—¶
    """
    images = []
    
    try:
        image_paths = json.loads(all_image_paths)
    except json.JSONDecodeError:
        logging.warning(f"æ— æ³•è§£æå›¾ç‰‡è·¯å¾„JSON: {all_image_paths}")
        image_paths = []
    
    # ç¡®å®šåŸºç¡€è·¯å¾„
    base_path = Path(dataset_path).parent if dataset_path.endswith('.csv') else Path(dataset_path)
    
    # åŠ è½½æ¯å¼ å›¾ç‰‡
    for image_path in image_paths:
        try:
            full_img_path = base_path / image_path
            
            # ä½¿ç”¨withè¯­å¥ç¡®ä¿å›¾åƒæ–‡ä»¶å¥æŸ„è¢«æ­£ç¡®å…³é—­
            with Image.open(full_img_path) as img:
                # åˆ›å»ºå‰¯æœ¬å¹¶è½¬æ¢ä¸ºRGBæ ¼å¼ï¼Œé¿å…æ‡’åŠ è½½é—®é¢˜
                image = img.convert("RGB").copy()
                
                # é™åˆ¶å›¾åƒæœ€å¤§å°ºå¯¸ä»¥å‡å°‘æ˜¾å­˜å ç”¨
                max_size = 1024
                if max(image.size) > max_size:
                    image.thumbnail((max_size, max_size), Image.Resampling.LANCZOS)
                    
                images.append(image)
                
        except FileNotFoundError:
            logging.error(f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {full_img_path}")
            continue
        except Exception as e:
            logging.error(f"åŠ è½½å›¾ç‰‡æ—¶å‡ºé”™ {image_path}: {e}")
            continue
    
    # å¦‚æœæ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•å›¾ç‰‡ï¼Œåˆ›å»ºå ä½å›¾ç‰‡
    if not images:
        placeholder = Image.new('RGB', (224, 224), color='white') # ä½¿ç”¨æ ‡å‡†å°ºå¯¸çš„ç™½è‰²å ä½å›¾ç‰‡
        images.append(placeholder)
        # logging.info("ä½¿ç”¨ç™½è‰²å ä½å›¾ç‰‡")
    
    return images


# =============================================================================
# æ•°æ®æ•´ç†å™¨ (Data Collator)
# =============================================================================

def collate_fn(examples: List[Dict[str, Any]]) -> Dict[str, torch.Tensor]:
    """
    æ•°æ®æ•´ç†å‡½æ•°ï¼Œå°†æ‰¹æ¬¡æ ·æœ¬è½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥æ ¼å¼ã€‚
    
    æ­¤å‡½æ•°æ˜¯è®­ç»ƒæµç¨‹çš„å…³é”®ç»„ä»¶ï¼Œè´Ÿè´£ï¼š
    1. åº”ç”¨å¯¹è¯æ¨¡æ¿å¹¶åˆ†è¯åŒ–æ–‡æœ¬
    2. å¤„ç†å›¾åƒæ•°æ®
    3. åˆ›å»ºè®­ç»ƒæ ‡ç­¾å¹¶é®è”½ç‰¹æ®Štoken
    4. å†…å­˜ç®¡ç†å’Œæ˜¾å­˜æ¸…ç†
    
    Args:
        examples (List[Dict[str, Any]]): æ‰¹æ¬¡æ ·æœ¬åˆ—è¡¨ï¼Œæ¯ä¸ªæ ·æœ¬åŒ…å«messageså’Œimages
        
    Returns:
        Dict[str, torch.Tensor]: æ¨¡å‹è®­ç»ƒæ‰€éœ€çš„æ‰¹æ¬¡æ•°æ®ï¼ŒåŒ…å«ï¼š
            - input_ids: åˆ†è¯åçš„è¾“å…¥åºåˆ—
            - attention_mask: æ³¨æ„åŠ›æ©ç 
            - pixel_values: å›¾åƒåƒç´ å€¼
            - labels: è®­ç»ƒæ ‡ç­¾ï¼ˆé®è”½äº†paddingå’Œå›¾åƒtokenï¼‰
            
    Note:
        - ä¼šè‡ªåŠ¨é®è”½padding tokenå’Œå›¾åƒtokençš„æŸå¤±è®¡ç®—
        - æ”¯æŒå¯é€‰çš„å‘¨æœŸæ€§å†…å­˜æ¸…ç†åŠŸèƒ½
        - åœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­åªåœ¨rank 0æ‰“å°è°ƒè¯•ä¿¡æ¯
    """
    # 1. åº”ç”¨å¯¹è¯æ¨¡æ¿å¹¶æå–æ–‡æœ¬å’Œå›¾åƒ
    texts = [processor.apply_chat_template(example["messages"], tokenize=False) 
             for example in examples]
    images = [example["images"] for example in examples]

    # 2. åˆ†è¯åŒ–æ–‡æœ¬å¹¶å¤„ç†å›¾åƒ
    batch = processor(text=texts, images=images, return_tensors="pt", padding=True)

    # 3. åˆ›å»ºè®­ç»ƒæ ‡ç­¾
    labels = batch["input_ids"].clone()
    
    # é®è”½padding tokenï¼Œä¸å‚ä¸æŸå¤±è®¡ç®—
    labels[labels == processor.tokenizer.pad_token_id] = -100
    
    # é®è”½å›¾åƒtokenï¼Œä¸å‚ä¸æŸå¤±è®¡ç®—ï¼ˆæ¨¡å‹ç‰¹å®šï¼‰
    image_token_id = processor.tokenizer.convert_tokens_to_ids(processor.image_token)
    labels[labels == image_token_id] = -100
    
    batch["labels"] = labels
    
    # 4. æ¸…ç†ä¸­é—´å˜é‡ï¼Œé‡Šæ”¾å†…å­˜
    del texts, images, labels

    # 5. å¯é€‰çš„å‘¨æœŸæ€§å†…å­˜æ¸…ç†
    _perform_optional_cleanup(examples)

    return batch


def _perform_optional_cleanup(examples: List[Dict[str, Any]]) -> None:
    """
    æ‰§è¡Œå¯é€‰çš„å‘¨æœŸæ€§å†…å­˜æ¸…ç†ã€‚
    
    é€šè¿‡ç¯å¢ƒå˜é‡CLEANUP_EVERY_Næ§åˆ¶æ¸…ç†é¢‘ç‡ï¼Œä»…åœ¨ä¸»è¿›ç¨‹ä¸­æ‰§è¡Œï¼Œ
    é¿å…åœ¨DataLoader workerè¿›ç¨‹ä¸­è¿›è¡ŒCUDAæ¸…ç†å¯¼è‡´çš„é—®é¢˜ã€‚
    
    Args:
        examples (List[Dict[str, Any]]): å½“å‰æ‰¹æ¬¡çš„æ ·æœ¬ï¼Œç”¨äºè°ƒè¯•è¾“å‡º
        
    Note:
        - ä»…åœ¨CLEANUP_EVERY_N > 0æ—¶å¯ç”¨
        - åªåœ¨ä¸»è¿›ç¨‹ä¸­æ‰§è¡Œï¼ˆworker_info is Noneï¼‰
        - åªåœ¨rank 0è¿›ç¨‹ä¸­æ‰“å°è°ƒè¯•ä¿¡æ¯
    """
    try:
        from torch.utils.data import get_worker_info
        worker_info = get_worker_info()
    except Exception:
        worker_info = None

    # åªåœ¨ä¸»è¿›ç¨‹ä¸­æ‰§è¡Œæ¸…ç†ï¼Œä½†æ˜¯æ¯ä¸ªGPUè¿›ç¨‹éƒ½ä¼šæ‰§è¡Œè‡ªå·±çš„æ¸…ç†
    if worker_info is None:
        global _collate_batch_count
        _collate_batch_count += 1
        
        if CLEANUP_EVERY_N > 0 and (_collate_batch_count % CLEANUP_EVERY_N == 0):
            # è·å–è¿›ç¨‹rankä¿¡æ¯
            try:
                import torch.distributed as dist
                rank = dist.get_rank() if dist.is_initialized() else int(os.getenv("RANK", "0"))
            except Exception:
                rank = int(os.getenv("RANK", "0"))
            
            device_str = f"cuda:{torch.cuda.current_device()}" if torch.cuda.is_available() else "cpu"

            # åªåœ¨rank 0æ‰“å°è°ƒè¯•ä¿¡æ¯
            if rank == 0:
                logging.info(f"\n[rank={rank} device={device_str}] ğŸ” æ¸…ç†å‰æ˜¾å­˜çŠ¶æ€ï¼š")
                os.system("nvidia-smi --query-gpu=index,name,utilization.gpu,memory.used,memory.total "
                         "--format=csv,noheader,nounits")
                logging.info(f"[rank={rank} device={device_str}] ğŸ” æ¸…ç†å†…å­˜: {_collate_batch_count} ä¸ª batch")
                logging.info(f"[rank={rank} device={device_str}] ç¬¬ä¸€ä¸ªæ ·æœ¬: {examples[0]}")

            # æ‰§è¡Œå†…å­˜å’Œæ˜¾å­˜æ¸…ç†
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

            if rank == 0:
                logging.info(f"[rank={rank} device={device_str}] ğŸ” æ¸…ç†åæ˜¾å­˜çŠ¶æ€ï¼š")
                os.system("nvidia-smi --query-gpu=index,name,utilization.gpu,memory.used,memory.total "
                         "--format=csv,noheader,nounits")


# =============================================================================
# å…¨å±€å˜é‡å’Œé…ç½®
# =============================================================================

# å‘¨æœŸæ€§å†…å­˜æ¸…ç†é…ç½®ï¼ˆé€šè¿‡ç¯å¢ƒå˜é‡æ§åˆ¶ï¼‰
CLEANUP_EVERY_N = int(os.getenv("CLEANUP_EVERY_N", "0"))
_collate_batch_count = 0  # ä»…åœ¨ä¸»è¿›ç¨‹ä¸­é€’å¢

# å…¨å±€å¤„ç†å™¨å˜é‡ï¼ˆåœ¨ä¸»å‡½æ•°ä¸­åˆå§‹åŒ–ï¼‰
processor: Optional[AutoProcessor] = None


# =============================================================================
# ä¸»è®­ç»ƒæµç¨‹
# =============================================================================

def main() -> None:
    """
    ä¸»è®­ç»ƒå‡½æ•°ã€‚
    
    æ‰§è¡Œå®Œæ•´çš„æ¨¡å‹è®­ç»ƒæµç¨‹ï¼ŒåŒ…æ‹¬ï¼š
    1. è§£æå‘½ä»¤è¡Œå‚æ•°å’Œé…ç½®
    2. åˆå§‹åŒ–æ¨¡å‹ã€å¤„ç†å™¨å’Œåˆ†è¯å™¨
    3. åŠ è½½å’Œé¢„å¤„ç†æ•°æ®é›†
    4. é…ç½®å’Œå¯åŠ¨è®­ç»ƒ
    5. ä¿å­˜æ¨¡å‹å’Œæ¨é€åˆ°Hub
    """
    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = TrlParser((ScriptArguments, SFTConfig, ModelConfig))
    script_args, training_args, model_args = parser.parse_args_and_config()
    
    # é…ç½®è®­ç»ƒå‚æ•°
    training_args.gradient_checkpointing_kwargs = dict(use_reentrant=False)
    training_args.remove_unused_columns = False
    training_args.dataset_kwargs = {"skip_prepare_dataset": True}
    
    logging.info("å¼€å§‹åˆå§‹åŒ–æ¨¡å‹å’Œå¤„ç†å™¨...")
    
    # åˆå§‹åŒ–æ¨¡å‹ã€åˆ†è¯å™¨å’Œå¤„ç†å™¨
    global processor
    processor, model = _initialize_model_and_processor(model_args)
    
    logging.info("å¼€å§‹åŠ è½½å’Œé¢„å¤„ç†æ•°æ®é›†...")

    # åªåœ¨ä¸»è¿›ç¨‹ä¸­è®¡ç®—æ•°æ®é¢„å¤„ç†ï¼Œæé«˜æ•ˆç‡
    # å‚è€ƒ: https://github.com/huggingface/trl/pull/1255
    state = PartialState()
    with state.local_main_process_first():
        # åŠ è½½å’Œé¢„å¤„ç†æ•°æ®é›†
        dataset = _load_and_prepare_dataset(script_args)
    
    logging.info("å¼€å§‹é…ç½®è®­ç»ƒå™¨...")
    
    # è®­ç»ƒå‰å†…å­˜æ¸…ç†
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    
    # é…ç½®è®­ç»ƒå™¨
    trainer = SFTTrainer(
        model=model,
        args=training_args,
        data_collator=collate_fn,
        train_dataset=dataset[script_args.dataset_train_split],
        eval_dataset=dataset[script_args.dataset_test_split] if training_args.eval_strategy != "no" else None,
        processing_class=processor.tokenizer,
        peft_config=get_peft_config(model_args),
    )

    logging.info("å¼€å§‹è®­ç»ƒ...")
    trainer.train()

    logging.info("è®­ç»ƒå®Œæˆï¼Œä¿å­˜æ¨¡å‹...")
    _save_and_upload_model(trainer, training_args, script_args)
    
    logging.info("è®­ç»ƒæµç¨‹å…¨éƒ¨å®Œæˆï¼")


def _initialize_model_and_processor(model_args: ModelConfig) -> Tuple[AutoProcessor, PreTrainedModel]:
    """
    åˆå§‹åŒ–æ¨¡å‹å’Œå¤„ç†å™¨ã€‚
    
    Args:
        model_args (ModelConfig): æ¨¡å‹é…ç½®å‚æ•°
        
    Returns:
        Tuple[AutoProcessor, PreTrainedModel]: (processor, model) å¤„ç†å™¨å’Œæ¨¡å‹å¯¹è±¡
        
    Raises:
        ValueError: å½“æ¨¡å‹é…ç½®å‚æ•°æ— æ•ˆæ—¶
        OSError: å½“æ¨¡å‹æ–‡ä»¶æ— æ³•åŠ è½½æ—¶
    """
    # ç¡®å®šæ•°æ®ç±»å‹
    torch_dtype = (
        model_args.torch_dtype 
        if model_args.torch_dtype in ["auto", None] 
        else getattr(torch, model_args.torch_dtype)
    )
    
    # è·å–é‡åŒ–é…ç½®
    quantization_config = get_quantization_config(model_args)
    
    # æ„å»ºæ¨¡å‹å‚æ•°
    model_kwargs = dict(
        revision=model_args.model_revision,
        attn_implementation=model_args.attn_implementation,
        torch_dtype=torch_dtype,
        # æ³¨é‡Šæ‰device_mapä»¥é¿å…ä¸DeepSpeedå†²çª
        # device_map=get_kbit_device_map() if quantization_config is not None else None,
        quantization_config=quantization_config,
    )
    
    try:
        # åŠ è½½å¤„ç†å™¨
        processor = AutoProcessor.from_pretrained(
            model_args.model_name_or_path, 
            trust_remote_code=model_args.trust_remote_code
        )

        # åŠ è½½æ¨¡å‹
        model = AutoModelForImageTextToText.from_pretrained(
            model_args.model_name_or_path, 
            trust_remote_code=model_args.trust_remote_code, 
            **model_kwargs
        )
        
        logging.info(f"æˆåŠŸåŠ è½½æ¨¡å‹: {model_args.model_name_or_path}")
        return processor, model
        
    except Exception as e:
        logging.error(f"åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
        raise OSError(f"æ— æ³•åŠ è½½æ¨¡å‹ {model_args.model_name_or_path}: {e}") from e


def _load_and_prepare_dataset(script_args: ScriptArguments) -> DatasetDict:
    """
    åŠ è½½å’Œé¢„å¤„ç†æ•°æ®é›†ã€‚
    
    Args:
        script_args (ScriptArguments): è„šæœ¬å‚æ•°é…ç½®
        
    Returns:
        DatasetDict: é¢„å¤„ç†åçš„æ•°æ®é›†
        
    Raises:
        FileNotFoundError: å½“æ•°æ®é›†æ–‡ä»¶ä¸å­˜åœ¨æ—¶
        ValueError: å½“æ•°æ®é›†æ ¼å¼ä¸æ­£ç¡®æ—¶
    """
    try:
        if script_args.dataset_name.endswith('.csv'):
            # ä»CSVæ–‡ä»¶åŠ è½½æ•°æ®é›†
            if not Path(script_args.dataset_name).exists():
                raise FileNotFoundError(f"æ•°æ®é›†æ–‡ä»¶ä¸å­˜åœ¨: {script_args.dataset_name}")
            
            dataset = load_dataset('csv', data_files=script_args.dataset_name)
            dataset = prepare_dataset(
                dataset, 
                script_args.dataset_name, 
                script_args.dataset_train_split, 
                templates=None
            )
            logging.info("æˆåŠŸä»CSVæ–‡ä»¶åŠ è½½æ•°æ®é›†")
        else:
            # ä»HuggingFace HubåŠ è½½æ•°æ®é›†
            dataset = load_dataset(
                script_args.dataset_name, 
                name=script_args.dataset_config
            )
            logging.info("æˆåŠŸä»HuggingFace HubåŠ è½½æ•°æ®é›†")
    
        return dataset
        
    except Exception as e:
        logging.error(f"åŠ è½½æ•°æ®é›†å¤±è´¥: {e}")
        if isinstance(e, FileNotFoundError):
            raise
        else:
            raise ValueError(f"æ•°æ®é›†æ ¼å¼é”™è¯¯æˆ–åŠ è½½å¤±è´¥: {e}") from e


def _save_and_upload_model(
    trainer: SFTTrainer, 
    training_args: SFTConfig, 
    script_args: ScriptArguments
) -> None:
    """
    ä¿å­˜æ¨¡å‹å¹¶å¯é€‰åœ°ä¸Šä¼ åˆ°Hubã€‚
    
    Args:
        trainer (SFTTrainer): è®­ç»ƒå™¨å¯¹è±¡
        training_args (SFTConfig): è®­ç»ƒé…ç½®
        script_args (ScriptArguments): è„šæœ¬å‚æ•°
        
    Raises:
        OSError: å½“æ¨¡å‹ä¿å­˜å¤±è´¥æ—¶
        ConnectionError: å½“æ¨é€åˆ°Hubå¤±è´¥æ—¶
    """
    try:
        # ä¿å­˜æ¨¡å‹
        trainer.save_model(training_args.output_dir)
        logging.info(f"æ¨¡å‹å·²ä¿å­˜åˆ°: {training_args.output_dir}")
        
        # å¯é€‰åœ°æ¨é€åˆ°Hub
        if training_args.push_to_hub:
            try:
                trainer.push_to_hub(dataset_name=script_args.dataset_name)
                
                # åªåœ¨ä¸»è¿›ç¨‹ä¸­æ¨é€å¤„ç†å™¨
                if trainer.accelerator.is_main_process:
                    if processor is not None:
                        processor.push_to_hub(training_args.hub_model_id)
                        logging.info(f"æ¨¡å‹å’Œå¤„ç†å™¨å·²æ¨é€åˆ°Hub: {training_args.hub_model_id}")
                    else:
                        logging.warning("å¤„ç†å™¨ä¸ºNoneï¼Œæ— æ³•æ¨é€åˆ°Hub")
                        
            except Exception as e:
                logging.error(f"æ¨é€åˆ°Hubå¤±è´¥: {e}")
                raise ConnectionError(f"æ— æ³•æ¨é€æ¨¡å‹åˆ°Hub: {e}") from e
                
    except Exception as e:
        if not isinstance(e, ConnectionError):
            logging.error(f"ä¿å­˜æ¨¡å‹å¤±è´¥: {e}")
            raise OSError(f"æ— æ³•ä¿å­˜æ¨¡å‹åˆ° {training_args.output_dir}: {e}") from e
        else:
            raise


if __name__ == "__main__":
    main()
