import torch
import json
import re
from typing import List, Optional, Dict, Union
from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor
from qwen_vl_utils import process_vision_info
from datasets import load_dataset
from pathlib import Path

class RiskAssessmentInference:
    """æˆ¿å±‹åˆ†æˆ·æ£€æŸ¥é£é™©è¯„ä¼°æ¨ç†ç±»"""
    
    def __init__(self, model_path: str, device: str = "auto", processor_path: str = None):
        """
        åˆå§‹åŒ–æ¨ç†æ¨¡å‹
        
        Args:
            model_path: æ¨¡å‹è·¯å¾„
            device: è®¾å¤‡ç±»å‹ï¼Œé»˜è®¤"auto"
            processor_path: processoré…ç½®è·¯å¾„ï¼Œé»˜è®¤ä¸model_pathç›¸åŒ
        """
        self.model_path = model_path
        self.processor_path = processor_path or model_path
        self.device = device
        self.model = None
        self.processor = None
        self._load_model()
    
    def _load_model(self):
        """åŠ è½½æ¨¡å‹å’Œå¤„ç†å™¨"""
        try:
            # åŠ è½½æ¨¡å‹
            self.model = Qwen2_5_VLForConditionalGeneration.from_pretrained(
                self.model_path, 
                torch_dtype="auto", 
                device_map=self.device
            )
            
            # åŠ è½½å¤„ç†å™¨
            self.processor = AutoProcessor.from_pretrained(self.processor_path)
            
            print(f"æ¨¡å‹åŠ è½½æˆåŠŸï¼š{self.model_path}")
            if self.processor_path != self.model_path:
                print(f"å¤„ç†å™¨è·¯å¾„ï¼š{self.processor_path}")
            
        except Exception as e:
            raise Exception(f"æ¨¡å‹åŠ è½½å¤±è´¥ï¼š{str(e)}")
    
    def _build_messages_with_images(self, image_paths: List[str]) -> List[Dict]:
        """
        æ„å»ºåŒ…å«å›¾åƒçš„æ¶ˆæ¯
        
        Args:
            image_paths: å›¾åƒè·¯å¾„åˆ—è¡¨
            
        Returns:
            messagesæ ¼å¼çš„æ•°æ®
        """
        image_count = len(image_paths)
        user_text = (
            "ä½œä¸ºæˆ¿å±‹åˆ†æˆ·æ£€æŸ¥ä¸“å®¶ï¼Œä½ ç°åœ¨æ­£åœ¨è¿›è¡Œåˆ†æˆ·æ£€æŸ¥åˆ†æã€‚"
            f"æœ¬æ¬¡åˆ†ææä¾›äº†{image_count}å¼ å›¾åƒã€‚æ ¹æ®æä¾›çš„{image_count}å¼ å›¾åƒï¼Œ"
            "è¯·åˆ†æå¯¹åº”çš„\"ç¼ºé™·\"ã€\"é£é™©\"ã€\"é£é™©ç­‰çº§ï¼ˆåŸæœ¬ï¼‰\"å’Œ\"é£é™©ç­‰çº§ï¼ˆç°åœ¨ï¼‰\"ï¼Œ"
            "å¹¶æä¾›\"çº æ­£å’Œé¢„é˜²å»ºè®®\"ã€‚\n"
            "è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼å›ç­”ï¼š\n"
            "ã€ç¼ºé™·ã€‘ï¼š\n"
            "ã€é£é™©ã€‘ï¼š\n"
            "ã€é£é™©ç­‰çº§ï¼ˆåŸæœ¬ï¼‰ã€‘ï¼š\n"
            "ã€é£é™©ç­‰çº§ï¼ˆç°åœ¨ï¼‰ã€‘ï¼š\n"
            "ã€çº æ­£å’Œé¢„é˜²å»ºè®®ã€‘ï¼š\n"
        )
        
        # æ„å»ºcontentåˆ—è¡¨
        content = [{"type": "text", "text": user_text}]
        
        # æ·»åŠ å›¾åƒ
        for image_path in image_paths:
            content.append({
                "type": "image", 
                "image": f"file://{image_path}"
            })
        
        messages = [
            {
                "role": "user",
                "content": content
            }
        ]
        
        return messages
    
    def _build_messages_with_text(self, defect_text: str) -> List[Dict]:
        """
        æ„å»ºåŒ…å«ç¼ºé™·æ–‡æœ¬çš„æ¶ˆæ¯
        
        Args:
            defect_text: ç¼ºé™·æè¿°æ–‡æœ¬
            
        Returns:
            messagesæ ¼å¼çš„æ•°æ®
        """
        user_text = (
            "ä½œä¸ºæˆ¿å±‹åˆ†æˆ·æ£€æŸ¥ä¸“å®¶ï¼Œä½ ç°åœ¨æ­£åœ¨è¿›è¡Œåˆ†æˆ·æ£€æŸ¥åˆ†æã€‚"
            f"æœ¬æ¬¡åˆ†ææ²¡æœ‰æä¾›å›¾åƒï¼ˆç©ºç™½å›¾åƒä½œä¸ºå ä½å›¾ç‰‡ï¼Œè¯·å¿½ç•¥ï¼‰ï¼Œä½†æ˜¯å·²çŸ¥\"ç¼ºé™·\"æ˜¯ï¼š{defect_text}ã€‚"
            "æ ¹æ®æä¾›çš„\"ç¼ºé™·\"æ–‡æœ¬ï¼Œè¯·åˆ†æå¯¹åº”çš„\"ç¼ºé™·\"ã€\"é£é™©\"ã€\"é£é™©ç­‰çº§ï¼ˆåŸæœ¬ï¼‰\"å’Œ\"é£é™©ç­‰çº§ï¼ˆç°åœ¨ï¼‰\"ï¼Œ"
            "å¹¶æä¾›\"çº æ­£å’Œé¢„é˜²å»ºè®®\"ã€‚\n"
            "è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼å›ç­”ï¼š\n"
            "ã€ç¼ºé™·ã€‘ï¼š\n"
            "ã€é£é™©ã€‘ï¼š\n"
            "ã€é£é™©ç­‰çº§ï¼ˆåŸæœ¬ï¼‰ã€‘ï¼š\n"
            "ã€é£é™©ç­‰çº§ï¼ˆç°åœ¨ï¼‰ã€‘ï¼š\n"
            "ã€çº æ­£å’Œé¢„é˜²å»ºè®®ã€‘ï¼š\n"
        )
        
        messages = [
            {
                "role": "user",
                "content": [{"type": "text", "text": user_text}]
            }
        ]
        
        return messages
    
    def _generate_response(self, messages: List[Dict]) -> str:
        """
        ç”Ÿæˆæ¨¡å‹å“åº”
        
        Args:
            messages: è¾“å…¥æ¶ˆæ¯
            
        Returns:
            æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬
        """
        try:
            # å‡†å¤‡æ¨ç†è¾“å…¥
            text = self.processor.apply_chat_template(
                messages, tokenize=False, add_generation_prompt=True
            )
            image_inputs, video_inputs = process_vision_info(messages)
            inputs = self.processor(
                text=[text],
                images=image_inputs,
                videos=video_inputs,
                padding=True,
                return_tensors="pt",
            )
            inputs = inputs.to(self.model.device)
            
            # ç”Ÿæˆå“åº”
            generated_ids = self.model.generate(**inputs, max_new_tokens=512)
            generated_ids_trimmed = [
                out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)
            ]
            output_text = self.processor.batch_decode(
                generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False
            )
            
            return output_text[0] if output_text else ""
            
        except Exception as e:
            raise Exception(f"ç”Ÿæˆå“åº”å¤±è´¥ï¼š{str(e)}")
    
    def _parse_response(self, response_text: str) -> Dict[str, str]:
        """
        è§£ææ¨¡å‹å“åº”ï¼Œæå–ç»“æ„åŒ–ä¿¡æ¯
        
        Args:
            response_text: æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬
            
        Returns:
            è§£æåçš„JSONæ ¼å¼æ•°æ®
        """
        result = {
            "ç¼ºé™·": "",
            "é£é™©": "",
            "é£é™©ç­‰çº§ï¼ˆåŸæœ¬ï¼‰": "",
            "é£é™©ç­‰çº§ï¼ˆç°åœ¨ï¼‰": "",
            "çº æ­£å’Œé¢„é˜²å»ºè®®": ""
        }
        
        # å®šä¹‰æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
        patterns = {
            "ç¼ºé™·": r"ã€ç¼ºé™·ã€‘ï¼š(.*?)(?=ã€|$)",
            "é£é™©": r"ã€é£é™©ã€‘ï¼š(.*?)(?=ã€|$)",
            "é£é™©ç­‰çº§ï¼ˆåŸæœ¬ï¼‰": r"ã€é£é™©ç­‰çº§ï¼ˆåŸæœ¬ï¼‰ã€‘ï¼š(.*?)(?=ã€|$)",
            "é£é™©ç­‰çº§ï¼ˆç°åœ¨ï¼‰": r"ã€é£é™©ç­‰çº§ï¼ˆç°åœ¨ï¼‰ã€‘ï¼š(.*?)(?=ã€|$)",
            "çº æ­£å’Œé¢„é˜²å»ºè®®": r"ã€çº æ­£å’Œé¢„é˜²å»ºè®®ã€‘ï¼š(.*?)(?=ã€|$)"
        }
        
        # æå–æ¯ä¸ªå­—æ®µ
        for key, pattern in patterns.items():
            match = re.search(pattern, response_text, re.DOTALL)
            if match:
                result[key] = match.group(1).strip()
        
        return result
    
    def inference_with_images(self, image_paths: List[str]) -> Dict[str, str]:
        """
        åŸºäºå›¾åƒè¿›è¡Œæ¨ç†
        
        Args:
            image_paths: å›¾åƒè·¯å¾„åˆ—è¡¨
            
        Returns:
            è§£æåçš„JSONæ ¼å¼ç»“æœ
        """
        if not image_paths:
            raise ValueError("å›¾åƒè·¯å¾„åˆ—è¡¨ä¸èƒ½ä¸ºç©º")
        
        # éªŒè¯å›¾åƒè·¯å¾„
        import os
        for image_path in image_paths:
            if not os.path.exists(image_path):
                raise FileNotFoundError(f"å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨ï¼š{image_path}")
        
        # æ„å»ºæ¶ˆæ¯
        messages = self._build_messages_with_images(image_paths)
        
        # ç”Ÿæˆå“åº”
        response_text = self._generate_response(messages)
        
        # è§£æå“åº”
        result = self._parse_response(response_text)
        
        return result
    
    def inference_with_text(self, defect_text: str) -> Dict[str, str]:
        """
        åŸºäºç¼ºé™·æ–‡æœ¬è¿›è¡Œæ¨ç†
        
        Args:
            defect_text: ç¼ºé™·æè¿°æ–‡æœ¬
            
        Returns:
            è§£æåçš„JSONæ ¼å¼ç»“æœ
        """
        if not defect_text.strip():
            raise ValueError("ç¼ºé™·æ–‡æœ¬ä¸èƒ½ä¸ºç©º")
        
        # æ„å»ºæ¶ˆæ¯
        messages = self._build_messages_with_text(defect_text)
        
        # ç”Ÿæˆå“åº”
        response_text = self._generate_response(messages)
        
        # è§£æå“åº”
        result = self._parse_response(response_text)
        
        return result


def create_inference_model(model_path: str, device: str = "auto", processor_path: str = None) -> RiskAssessmentInference:
    """
    åˆ›å»ºæ¨ç†æ¨¡å‹å®ä¾‹
    
    Args:
        model_path: æ¨¡å‹è·¯å¾„
        device: è®¾å¤‡ç±»å‹
        processor_path: processoré…ç½®è·¯å¾„ï¼Œé»˜è®¤ä¸model_pathç›¸åŒ
        
    Returns:
        æ¨ç†æ¨¡å‹å®ä¾‹
    """
    return RiskAssessmentInference(model_path, device, processor_path)


# ä¾¿æ·å‡½æ•°
def inference_with_images(model_path: str, image_paths: List[str], device: str = "auto", processor_path: str = None) -> Dict[str, str]:
    """
    åŸºäºå›¾åƒè¿›è¡Œé£é™©è¯„ä¼°æ¨ç†ï¼ˆä¾¿æ·å‡½æ•°ï¼‰
    
    Args:
        model_path: æ¨¡å‹è·¯å¾„
        image_paths: å›¾åƒè·¯å¾„åˆ—è¡¨
        device: è®¾å¤‡ç±»å‹
        processor_path: processoré…ç½®è·¯å¾„ï¼Œé»˜è®¤ä¸model_pathç›¸åŒ
        
    Returns:
        è§£æåçš„JSONæ ¼å¼ç»“æœ
    """
    model = RiskAssessmentInference(model_path, device, processor_path)
    return model.inference_with_images(image_paths)


def inference_with_text(model_path: str, defect_text: str, device: str = "auto", processor_path: str = None) -> Dict[str, str]:
    """
    åŸºäºç¼ºé™·æ–‡æœ¬è¿›è¡Œé£é™©è¯„ä¼°æ¨ç†ï¼ˆä¾¿æ·å‡½æ•°ï¼‰
    
    Args:
        model_path: æ¨¡å‹è·¯å¾„
        defect_text: ç¼ºé™·æè¿°æ–‡æœ¬
        device: è®¾å¤‡ç±»å‹
        processor_path: processoré…ç½®è·¯å¾„ï¼Œé»˜è®¤ä¸model_pathç›¸åŒ
        
    Returns:
        è§£æåçš„JSONæ ¼å¼ç»“æœ
    """
    model = RiskAssessmentInference(model_path, device, processor_path)
    return model.inference_with_text(defect_text)


# ç¤ºä¾‹ç”¨æ³•
if __name__ == "__main__":
    # ç¤ºä¾‹1ï¼šä½¿ç”¨ä¾¿æ·å‡½æ•°æ¨ç†(å›¾åƒæˆ–æ–‡æœ¬)

    # defect_text = "å¢™é¢å‡ºç°è£‚ç¼"
    # result = inference_with_text(model_path, defect_text)
    # print("æ–‡æœ¬æ¨ç†ç»“æœï¼š")
    # print(json.dumps(result, ensure_ascii=False, indent=2))

    # image_paths = ["path1", "path2", "path3"]
    # result = inference_with_images(model_path, image_paths)
    # print("å›¾åƒæ¨ç†ç»“æœï¼š")
    # print(json.dumps(result, ensure_ascii=False, indent=2))

    
    """ command: 
    python src/sft_subnunit_risk/inference.py 2>&1 | tee logs/inference_$(date +%Y%m%d_%H%M%S).log
    """

    # ç¤ºä¾‹2ï¼šåˆ›å»ºæ¨¡å‹å®ä¾‹å¤ç”¨(å›¾åƒæˆ–æ–‡æœ¬)

    pretrained_model_path = "models/pretrained_models/Qwen/Qwen2.5-VL-3B-Instruct"
    finetuned_model_path = "models/finetuned_models/RisKVA/RisKVA-Qwen2.5-VL-3B-Instruct-sft-subunit-risk"

    dataset_path = "datasets/RisKVA/Subunit-Risk_original/metadata_with_image.csv"
    if dataset_path.endswith('.csv'):
        dataset = load_dataset('csv', data_files=f'{dataset_path}')
    else:
        dataset = load_dataset(dataset_path)

    # é¢„è®­ç»ƒæ¨¡å‹
    pretrained_model = create_inference_model(pretrained_model_path)
    print("ğŸ”å›¾åƒæ¨ç†ç»“æœï¼ˆé¢„è®­ç»ƒæ¨¡å‹ï¼‰ï¼š")
    for i in range(len(dataset['train'])):
        print(f"ğŸ”ç¬¬{i}ä¸ªæ ·æœ¬ï¼š")
        print(dataset['train'][i])
        # åŠ è½½å›¾ç‰‡
        images = []

        all_image_paths = dataset['train'][i]['all_image_paths']
        image_paths = json.loads(all_image_paths)

        base_path = Path(dataset_path).parent if dataset_path.endswith('.csv') else Path(dataset_path)
        for image_path in image_paths:
            full_img_path = base_path / image_path
            images.append(full_img_path)

        result = pretrained_model.inference_with_images(images)
        print(f"ğŸ”æ ¹æ®ç¬¬{i}ä¸ªæ ·æœ¬çš„å›¾åƒï¼Œæ¨ç†ç»“æœï¼š")
        print(json.dumps(result, ensure_ascii=False, indent=2))
    
    # å¾®è°ƒæ¨¡å‹
    finetuned_model = create_inference_model(finetuned_model_path, processor_path=pretrained_model_path)
    print("ğŸ”å›¾åƒæ¨ç†ç»“æœï¼ˆå¾®è°ƒæ¨¡å‹ï¼‰ï¼š")
    for i in range(len(dataset['train'])):
        print(f"ğŸ”ç¬¬{i}ä¸ªæ ·æœ¬ï¼š")
        print(dataset['train'][i])
        images = []

        all_image_paths = dataset['train'][i]['all_image_paths']
        image_paths = json.loads(all_image_paths)

        base_path = Path(dataset_path).parent if dataset_path.endswith('.csv') else Path(dataset_path)
        for image_path in image_paths:
            full_img_path = base_path / image_path
            images.append(full_img_path)

        result = finetuned_model.inference_with_images(images)
        print(f"ğŸ”æ ¹æ®ç¬¬{i}ä¸ªæ ·æœ¬çš„å›¾åƒï¼Œæ¨ç†ç»“æœï¼š")
        print(json.dumps(result, ensure_ascii=False, indent=2))