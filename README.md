# Qwen2.5-VL å»ºç­‘é£é™©è¯†åˆ« SFT è®­ç»ƒæ¡†æ¶

åŸºäºQwen2.5-VLå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„å»ºç­‘ç¼ºé™·é£é™©è¯†åˆ«ç³»ç»Ÿï¼Œæ”¯æŒä»å›¾ç‰‡è‡ªåŠ¨è¯†åˆ«å»ºç­‘ç¼ºé™·å¹¶æä¾›ä¸“ä¸šçš„é£é™©è¯„ä¼°å’Œä¿®å¤å»ºè®®ã€‚

## ğŸš€ ç‰¹æ€§

- **å¤šæ¨¡æ€ç†è§£**: åŸºäºQwen2.5-VLï¼ŒåŒæ—¶ç†è§£å›¾åƒå’Œæ–‡æœ¬
- **ä¸“ä¸šåˆ†æ**: é’ˆå¯¹å»ºç­‘å·¥ç¨‹ç¼ºé™·è¿›è¡Œä¸“é—¨ä¼˜åŒ–
- **é«˜æ•ˆè®­ç»ƒ**: æ”¯æŒLoRAå¾®è°ƒï¼Œæ˜¾å­˜å‹å¥½
- **åˆ†å¸ƒå¼è®­ç»ƒ**: æ”¯æŒå¤šGPUå¹¶è¡Œè®­ç»ƒ
- **æ˜“äºéƒ¨ç½²**: å®Œæ•´çš„æ¨ç†æ¥å£ï¼Œæ”¯æŒæ‰¹é‡å¤„ç†
- **æ•°æ®æ ¼å¼å¤šæ ·**: æ”¯æŒJSONLå’ŒParquetä¸¤ç§æ•°æ®æ ¼å¼
- **æ•°æ®å®Œæ•´æ€§**: Parquetæ ¼å¼å°†å›¾ç‰‡å†…åµŒï¼Œé¿å…æ–‡ä»¶ä¸¢å¤±é—®é¢˜

## ğŸ“‹ ç¯å¢ƒè¦æ±‚

- Python 3.8+
- CUDA 11.8+ (GPUè®­ç»ƒ)
- 16GB+ GPUæ˜¾å­˜ (æ¨è24GB+)
- PyTorch 2.0+

## ğŸ› ï¸ å®‰è£…

1. å…‹éš†é¡¹ç›®ï¼š
```bash
git clone <your-repo-url>
cd RisKVA
```

2. å®‰è£…ä¾èµ–ï¼š
```bash
pip install -r requirements.txt
```

3. é…ç½®accelerateï¼š
```bash
accelerate config
```

## ğŸ“Š æ•°æ®æ ¼å¼

### åŸå§‹CSVæ•°æ®æ ¼å¼

è®­ç»ƒæ•°æ®åº”åŒ…å«ä»¥ä¸‹å­—æ®µï¼š
- `image_path`: å›¾ç‰‡ç›¸å¯¹è·¯å¾„
- `data_é£é™©`: é£é™©æè¿°
- `data_é£é™©ç­‰çº§`: é£é™©ç­‰çº§ï¼ˆè½»å¾®/ä¸­ç­‰/ä¸¥é‡ï¼‰
- `data_çº æ­£å’Œé¢„é˜²å»ºè®®`: ä¿®å¤å»ºè®®
- `data_ç¼ºé™·æè¿°`: ç¼ºé™·è¯¦ç»†æè¿°

ç¤ºä¾‹CSVæ ¼å¼ï¼š
```csv
image_id,image_path,data_é£é™©,data_çº æ­£å’Œé¢„é˜²å»ºè®®,data_é£é™©ç­‰çº§,data_ç¼ºé™·æè¿°
0,images/001.jpg,å¨æˆ¿ç”¨æ°´æ˜“æº…å…¥å¢™ä½“é€ æˆå¢™ä½“å‘éœ‰,å»ºè®®é€åº•å¤„è¡¥åˆ·é˜²æ°´æ¶‚æ–™,è½»å¾®,å¨æˆ¿å¢™é¢é˜²æ°´æ¶‚æ–™é€åº•
```

### å¤„ç†åæ•°æ®æ ¼å¼æ¯”è¾ƒ

| ç‰¹æ€§ | JSONLæ ¼å¼ | Parquetæ ¼å¼ï¼ˆæ¨èï¼‰ |
|------|-----------|-------------------|
| **å­˜å‚¨æ–¹å¼** | å›¾ç‰‡æ–‡ä»¶+æ–‡æœ¬æ–‡ä»¶åˆ†ç¦» | å›¾ç‰‡+æ–‡æœ¬ä¸€ä½“åŒ–å­˜å‚¨ |
| **æ•°æ®å®Œæ•´æ€§** | ä¾èµ–å¤–éƒ¨å›¾ç‰‡æ–‡ä»¶ | å†…åµŒbase64ç¼–ç å›¾ç‰‡ |
| **ä¼ è¾“ä¾¿åˆ©æ€§** | éœ€è¦åŒæ—¶ä¼ è¾“å¤šä¸ªæ–‡ä»¶ | å•æ–‡ä»¶åŒ…å«æ‰€æœ‰æ•°æ® |
| **å‹ç¼©æ•ˆç‡** | ä¸­ç­‰ | é«˜ï¼ˆsnappyå‹ç¼©ï¼‰ |
| **æŸ¥è¯¢æ€§èƒ½** | ä¸€èˆ¬ | ä¼˜ç§€ï¼ˆåˆ—å¼å­˜å‚¨ï¼‰ |
| **éšæœºè®¿é—®** | éœ€è¦éå† | æ”¯æŒé«˜æ•ˆç´¢å¼• |
| **æ–‡ä»¶å¤§å°** | è¾ƒå°ï¼ˆæ–‡æœ¬ï¼‰+åŸå§‹å›¾ç‰‡ | ä¸­ç­‰ï¼ˆå‹ç¼©åå›¾ç‰‡ï¼‰ |
| **é€‚ç”¨åœºæ™¯** | å¼€å‘æµ‹è¯• | ç”Ÿäº§éƒ¨ç½² |

## ğŸ¯ å¿«é€Ÿå¼€å§‹

### æ–¹æ¡ˆä¸€ï¼šJSONLæ ¼å¼ï¼ˆåŸç‰ˆï¼‰

#### 1. æ•°æ®é¢„å¤„ç†

```bash
python prepare_sft_data.py \
    --csv_path ./datasets/single_image_tiny_247/metadata.csv \
    --image_base_path ./datasets/single_image_tiny_247 \
    --output_path ./sft_data
```

#### 2. è®­ç»ƒæ¨¡å‹

```bash
bash run_training.sh
```

### æ–¹æ¡ˆäºŒï¼šParquetæ ¼å¼ï¼ˆæ¨èï¼‰

#### 1. æ•°æ®é¢„å¤„ç†ä¸ºParquetæ ¼å¼

```bash
python prepare_sft_data_parquet.py \
    --csv_path ./datasets/single_image_tiny_247/metadata.csv \
    --image_base_path ./datasets/single_image_tiny_247 \
    --output_path ./datasets/processed/single_image_parquet \
    --image_quality 85 \
    --max_image_size 1024 1024
```

#### 2. è®­ç»ƒæ¨¡å‹

```bash
bash run_training_parquet.sh
```

æˆ–æ‰‹åŠ¨æ‰§è¡Œï¼š
```bash
accelerate launch \
    --config_file configs/deepspeed_zero2.yaml \
    custom_sft_vlm.py \
    --model_name_or_path Qwen/Qwen2.5-VL-7B-Instruct \
    --dataset_path ./sft_data \
    --output_dir ./models/risk_detection_qwen25vl \
    --per_device_train_batch_size 2 \
    --gradient_accumulation_steps 8 \
    --num_train_epochs 3 \
    --learning_rate 5e-6 \
    --bf16 \
    --gradient_checkpointing \
    --use_lora True
```

### 3. æ¨¡å‹æ¨ç†

#### JSONLæ ¼å¼æ¨ç†ï¼š
å•å¼ å›¾ç‰‡æ¨ç†ï¼š
```bash
python inference.py \
    --model_path ./models/risk_detection_qwen25vl \
    --image_path ./test_image.jpg
```

æ‰¹é‡æ¨ç†ï¼š
```bash
python inference.py \
    --model_path ./models/risk_detection_qwen25vl \
    --image_list ./image_list.txt \
    --output_file ./results.json
```

#### Parquetæ ¼å¼æ¨ç†ï¼š
å•å¼ å›¾ç‰‡æ¨ç†ï¼š
```bash
python inference_parquet.py \
    --model_path ./models/risk_detection_qwen25vl_parquet \
    --image_path ./test_image.jpg
```

æ‰¹é‡æ¨ç†ï¼ˆä»Parquetæ–‡ä»¶ï¼‰ï¼š
```bash
python inference_parquet.py \
    --model_path ./models/risk_detection_qwen25vl_parquet \
    --parquet_file ./datasets/processed/single_image_parquet/test.parquet \
    --output_file ./results.json \
    --compare_gt
```

## âš™ï¸ è®­ç»ƒå‚æ•°è¯´æ˜

### å…³é”®å‚æ•°
- `per_device_train_batch_size`: æ¯ä¸ªGPUçš„æ‰¹å¤§å°
- `gradient_accumulation_steps`: æ¢¯åº¦ç´¯ç§¯æ­¥æ•°
- `learning_rate`: å­¦ä¹ ç‡ï¼Œå»ºè®®5e-6
- `num_train_epochs`: è®­ç»ƒè½®æ•°
- `use_lora`: æ˜¯å¦ä½¿ç”¨LoRAå¾®è°ƒ
- `lora_r`: LoRAç§©ï¼Œå½±å“å‚æ•°é‡

### LoRAé…ç½®
```bash
--use_lora True \
--lora_r 64 \
--lora_alpha 128 \
--lora_target_modules "q_proj,v_proj,k_proj,o_proj,gate_proj,up_proj,down_proj"
```

## ğŸ“ é¡¹ç›®ç»“æ„

```
RisKVA/
â”œâ”€â”€ prepare_sft_data.py          # æ•°æ®é¢„å¤„ç†è„šæœ¬
â”œâ”€â”€ custom_sft_vlm.py           # è‡ªå®šä¹‰SFTè®­ç»ƒè„šæœ¬  
â”œâ”€â”€ inference.py                # æ¨ç†è„šæœ¬
â”œâ”€â”€ convert_model.py           # æ¨¡å‹è½¬æ¢è„šæœ¬
â”œâ”€â”€ run_training.sh            # è®­ç»ƒå¯åŠ¨è„šæœ¬
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ deepspeed_zero2.yaml   # DeepSpeedé…ç½®
â”œâ”€â”€ datasets/                  # æ•°æ®é›†ç›®å½•
â””â”€â”€ models/                    # æ¨¡å‹è¾“å‡ºç›®å½•
```

## ğŸ—‚ï¸ Parquetæ ¼å¼è¯¦ç»†è¯´æ˜

### ä¼˜åŠ¿ç‰¹ç‚¹
1. **æ•°æ®å®Œæ•´æ€§**: å›¾ç‰‡ä»¥base64ç¼–ç å†…åµŒï¼Œæ— éœ€æ‹…å¿ƒæ–‡ä»¶ä¸¢å¤±
2. **é«˜æ•ˆå‹ç¼©**: ä½¿ç”¨snappyå‹ç¼©ï¼Œå­˜å‚¨æ•ˆç‡é«˜
3. **å¿«é€ŸåŠ è½½**: åˆ—å¼å­˜å‚¨ï¼Œæ”¯æŒé«˜æ•ˆæ•°æ®è®¿é—®
4. **ä¾¿äºä¼ è¾“**: å•æ–‡ä»¶åŒ…å«æ‰€æœ‰æ•°æ®ï¼Œæ˜“äºéƒ¨ç½²

### é¢„å¤„ç†å‚æ•°è¯´æ˜
```bash
--image_quality 85          # JPEGå‹ç¼©è´¨é‡(1-100)
--max_image_size 1024 1024  # å›¾ç‰‡æœ€å¤§å°ºå¯¸[å®½ é«˜]
```

### æ•°æ®é¢„è§ˆ
```bash
python prepare_sft_data_parquet.py --preview ./datasets/processed/single_image_parquet/train.parquet
```

### è®­ç»ƒæ—¶çš„é¢å¤–å‚æ•°
```bash
--cache_images True         # æ˜¯å¦é¢„å…ˆè§£ç å›¾ç‰‡åˆ°å†…å­˜
```

## ğŸ”§ å¸¸è§é—®é¢˜

### Q: æ˜¾å­˜ä¸å¤Ÿæ€ä¹ˆåŠï¼Ÿ
A: å¯ä»¥å°è¯•ï¼š
- å‡å°‘`per_device_train_batch_size`
- å¢åŠ `gradient_accumulation_steps` 
- ä½¿ç”¨DeepSpeed Zero-3
- å¼€å¯æ¢¯åº¦æ£€æŸ¥ç‚¹
- é™ä½å›¾ç‰‡è´¨é‡å’Œå°ºå¯¸ï¼ˆParquetæ ¼å¼ï¼‰

### Q: å¦‚ä½•è°ƒæ•´æ¨¡å‹è¾“å‡ºæ ¼å¼ï¼Ÿ
A: ä¿®æ”¹`prepare_sft_data.py`æˆ–`prepare_sft_data_parquet.py`ä¸­çš„`system_prompt`å’Œ`assistant_answer`æ ¼å¼

### Q: å¦‚ä½•æ·»åŠ æ›´å¤šè®­ç»ƒæ•°æ®ï¼Ÿ
A: æŒ‰ç…§CSVæ ¼å¼å‡†å¤‡æ•°æ®ï¼Œç¡®ä¿å›¾ç‰‡è·¯å¾„æ­£ç¡®

### Q: Parquetå’ŒJSONLæ ¼å¼å¦‚ä½•é€‰æ‹©ï¼Ÿ
A: 
- **å¼€å‘é˜¶æ®µ**: å»ºè®®ä½¿ç”¨JSONLæ ¼å¼ï¼Œæ–¹ä¾¿è°ƒè¯•
- **ç”Ÿäº§ç¯å¢ƒ**: å»ºè®®ä½¿ç”¨Parquetæ ¼å¼ï¼Œæ•°æ®å®Œæ•´æ€§å¥½
- **å¤§è§„æ¨¡æ•°æ®**: å¿…é¡»ä½¿ç”¨Parquetæ ¼å¼ï¼Œæ•ˆç‡æ›´é«˜

## ğŸ¨ è‡ªå®šä¹‰è¾“å‡ºæ ¼å¼

åœ¨`prepare_sft_data.py`ä¸­ä¿®æ”¹è¾“å‡ºæ ¼å¼ï¼š

```python
assistant_answer = f"""**é£é™©æè¿°**: {row['data_é£é™©']}
**é£é™©ç­‰çº§**: {row['data_é£é™©ç­‰çº§']}  
**çº æ­£å’Œé¢„é˜²å»ºè®®**: {row['data_çº æ­£å’Œé¢„é˜²å»ºè®®']}
**ç¼ºé™·æè¿°**: {row['data_ç¼ºé™·æè¿°']}
**ä½ç½®ä¿¡æ¯**: {row.get('ä½ç½®', 'æœªçŸ¥')}  # å¯æ·»åŠ æ›´å¤šå­—æ®µ
"""
```

## ğŸ“ˆ è®­ç»ƒç›‘æ§

æ”¯æŒTensorBoardå’ŒWandBç›‘æ§ï¼š

```bash
# TensorBoard
tensorboard --logdir ./models/risk_detection_qwen25vl/runs

# WandB (éœ€è¦ç™»å½•)
wandb login
```

## ğŸš€ éƒ¨ç½²å»ºè®®

1. **ç”Ÿäº§ç¯å¢ƒ**: ä½¿ç”¨åˆå¹¶åçš„æ¨¡å‹ä»¥æé«˜æ¨ç†é€Ÿåº¦
2. **APIæœåŠ¡**: å¯ä»¥åŸºäºFastAPIå°è£…æ¨ç†æ¥å£
3. **æ‰¹é‡å¤„ç†**: ä½¿ç”¨æ‰¹é‡æ¨ç†è„šæœ¬å¤„ç†å¤§é‡å›¾ç‰‡

## ğŸ“ License

æœ¬é¡¹ç›®éµå¾ªApache 2.0è®¸å¯è¯ã€‚

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤Issueå’ŒPull Requestï¼

---

## ğŸ’¡ æŠ€æœ¯åŸç†

### SFTè®­ç»ƒæµç¨‹
1. **æ•°æ®é¢„å¤„ç†**: å°†CSVæ•°æ®è½¬æ¢ä¸ºå¯¹è¯æ ¼å¼
2. **æ¨¡å‹åŠ è½½**: åŠ è½½Qwen2.5-VLé¢„è®­ç»ƒæ¨¡å‹
3. **LoRAå¾®è°ƒ**: ä½¿ç”¨å‚æ•°é«˜æ•ˆå¾®è°ƒå‡å°‘æ˜¾å­˜å ç”¨
4. **å¤šGPUè®­ç»ƒ**: ä½¿ç”¨DeepSpeedè¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒ

### æ•°æ®æ ¼å¼è½¬æ¢
åŸå§‹æ•°æ® â†’ å¯¹è¯æ ¼å¼ â†’ TokenåŒ– â†’ æ¨¡å‹è®­ç»ƒ

### æ¨ç†è¿‡ç¨‹  
å›¾ç‰‡è¾“å…¥ â†’ è§†è§‰ç¼–ç  â†’ å¤šæ¨¡æ€èåˆ â†’ æ–‡æœ¬ç”Ÿæˆ â†’ ç»“æ„åŒ–è¾“å‡º
