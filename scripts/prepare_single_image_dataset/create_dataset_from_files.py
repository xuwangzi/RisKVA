#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®Œæ•´æ•°æ®é›†åˆ›å»ºè„šæœ¬
ä»PDFå’ŒXLSXæ–‡ä»¶ä¸€é”®ç”ŸæˆHugging Faceæ•°æ®é›†

å·¥ä½œæµç¨‹ï¼š
1. æ‰«æè¾“å…¥ç›®å½•ä¸­çš„PDFå’ŒXLSXæ–‡ä»¶
2. å°†XLSXè½¬æ¢ä¸ºCSVï¼ŒPDFæå–å›¾ç‰‡ (ä½¿ç”¨get_text_image.pyåŠŸèƒ½)
3. å°†å›¾ç‰‡å’ŒCSVæ•°æ®æ•´ç†ä¸ºæ ‡å‡†æ•°æ®é›†æ ¼å¼ (ä½¿ç”¨get_datasets.pyåŠŸèƒ½)
"""

import sys
import os
import argparse
import tempfile
import shutil
from pathlib import Path

# å¯¼å…¥éœ€è¦çš„æ¨¡å—åŠŸèƒ½
try:
    # å¯¼å…¥ get_text_image.py çš„åŠŸèƒ½
    from get_text_image import (
        excel_to_csv, 
        extract_images_from_pdf, 
        scan_input_directory as scan_files,
        clean_text,
        process_excel_data
    )
    
    # å¯¼å…¥ get_datasets.py çš„åŠŸèƒ½  
    from get_datasets import (
        scan_images,
        scan_csv_files,
        load_csv_data,
        match_images_with_data,
        copy_images_to_dataset,
        create_metadata_csv,
        create_dataset_info,
        create_readme,
        create_dataset_structure
    )
    
    print("âœ… æˆåŠŸå¯¼å…¥æ‰€éœ€æ¨¡å—")
    
except ImportError as e:
    print(f"âŒ å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿ get_text_image.py å’Œ get_datasets.py åœ¨åŒä¸€ç›®å½•ä¸‹")
    sys.exit(1)


def get_script_directory():
    """è·å–è„šæœ¬æ‰€åœ¨ç›®å½•"""
    return os.path.dirname(os.path.abspath(__file__))


def step1_convert_files(input_dir: str, temp_dir: str) -> tuple:
    """
    æ­¥éª¤1: è½¬æ¢åŸå§‹æ–‡ä»¶
    å°†PDFæå–å›¾ç‰‡ï¼ŒXLSXè½¬æ¢ä¸ºCSV
    
    Args:
        input_dir: è¾“å…¥ç›®å½•
        temp_dir: ä¸´æ—¶å·¥ä½œç›®å½•
        
    Returns:
        tuple: (æˆåŠŸè½¬æ¢çš„æ–‡ä»¶æ•°, è½¬æ¢åçš„æ–‡ä»¶è·¯å¾„)
    """
    print("=" * 60)
    print("ğŸ“ æ­¥éª¤1: è½¬æ¢åŸå§‹æ–‡ä»¶")
    print("=" * 60)
    
    # åˆ›å»ºä¸´æ—¶ç›®å½•ç»“æ„
    temp_csv_dir = os.path.join(temp_dir, "csv")
    temp_images_dir = os.path.join(temp_dir, "images")
    os.makedirs(temp_csv_dir, exist_ok=True)
    os.makedirs(temp_images_dir, exist_ok=True)
    
    # æ‰«æè¾“å…¥æ–‡ä»¶
    xlsx_files, pdf_files = scan_files(input_dir)
    
    print(f"å‘ç°æ–‡ä»¶:")
    print(f"  ğŸ“Š Excelæ–‡ä»¶: {len(xlsx_files)} ä¸ª")
    print(f"  ğŸ“„ PDFæ–‡ä»¶: {len(pdf_files)} ä¸ª")
    print()
    
    if not xlsx_files and not pdf_files:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•XLSXæˆ–PDFæ–‡ä»¶")
        return 0, None
    
    successful_conversions = 0
    
    # å¤„ç†Excelæ–‡ä»¶è½¬CSV
    if xlsx_files:
        print("ğŸ”„ è½¬æ¢Excelæ–‡ä»¶...")
        for xlsx_file in xlsx_files:
            result = excel_to_csv(xlsx_file, temp_csv_dir)
            if result:
                successful_conversions += 1
                print(f"  âœ… {os.path.basename(xlsx_file)} -> CSV")
            else:
                print(f"  âŒ {os.path.basename(xlsx_file)} è½¬æ¢å¤±è´¥")
        print()
    
    # å¤„ç†PDFæ–‡ä»¶æå–å›¾ç‰‡
    if pdf_files:
        print("ğŸ–¼ï¸  æå–PDFå›¾ç‰‡...")
        for pdf_file in pdf_files:
            images = extract_images_from_pdf(pdf_file, temp_images_dir)
            if images:
                successful_conversions += 1
                print(f"  âœ… {os.path.basename(pdf_file)} -> {len(images)} å¼ å›¾ç‰‡")
            else:
                print(f"  âŒ {os.path.basename(pdf_file)} å¤„ç†å¤±è´¥")
        print()
    
    print(f"ğŸ“Š è½¬æ¢ç»Ÿè®¡:")
    print(f"  æˆåŠŸå¤„ç†: {successful_conversions}/{len(xlsx_files) + len(pdf_files)} ä¸ªæ–‡ä»¶")
    print(f"  CSVæ–‡ä»¶ç›®å½•: {temp_csv_dir}")
    print(f"  å›¾ç‰‡æ–‡ä»¶ç›®å½•: {temp_images_dir}")
    
    return successful_conversions, temp_dir


def step2_create_dataset(temp_dir: str, output_dir: str) -> bool:
    """
    æ­¥éª¤2: åˆ›å»ºæ•°æ®é›†
    å°†è½¬æ¢åçš„å›¾ç‰‡å’ŒCSVæ•´ç†ä¸ºæ ‡å‡†æ•°æ®é›†æ ¼å¼
    
    Args:
        temp_dir: ä¸´æ—¶ç›®å½•ï¼ˆåŒ…å«è½¬æ¢åçš„æ–‡ä»¶ï¼‰
        output_dir: æœ€ç»ˆæ•°æ®é›†è¾“å‡ºç›®å½•
        
    Returns:
        bool: æ˜¯å¦æˆåŠŸåˆ›å»ºæ•°æ®é›†
    """
    print("\n" + "=" * 60)
    print("ğŸ¯ æ­¥éª¤2: åˆ›å»ºæ ‡å‡†æ•°æ®é›†")
    print("=" * 60)
    
    # æ‰«æè½¬æ¢åçš„æ–‡ä»¶
    temp_csv_dir = os.path.join(temp_dir, "csv")
    temp_images_dir = os.path.join(temp_dir, "images")
    
    # æ‰«æå›¾ç‰‡æ–‡ä»¶
    print("ğŸ” æ‰«æè½¬æ¢åçš„æ–‡ä»¶...")
    image_files = scan_images(temp_images_dir)
    csv_files = scan_csv_files(temp_csv_dir)
    
    print(f"  ğŸ“· æ‰¾åˆ°å›¾ç‰‡: {len(image_files)} å¼ ")
    print(f"  ğŸ“Š æ‰¾åˆ°CSV: {len(csv_files)} ä¸ª")
    
    if not image_files or not csv_files:
        print("âŒ è½¬æ¢åçš„æ–‡ä»¶ä¸è¶³ï¼Œæ— æ³•åˆ›å»ºæ•°æ®é›†")
        return False
    
    # åŠ è½½CSVæ•°æ®
    print("\nğŸ“– åŠ è½½CSVæ•°æ®...")
    csv_data = load_csv_data(csv_files)
    
    if csv_data.empty:
        print("âŒ æ— æ³•åŠ è½½CSVæ•°æ®")
        return False
    
    # åŒ¹é…å›¾ç‰‡ä¸æ•°æ®
    print("\nğŸ”— åŒ¹é…å›¾ç‰‡ä¸æ•°æ®...")
    matched_data = match_images_with_data(image_files, csv_data)
    
    if not matched_data:
        print("âŒ æ— æ³•åŒ¹é…å›¾ç‰‡ä¸æ•°æ®")
        return False
    
    # åˆ›å»ºæ•°æ®é›†ç»“æ„
    print(f"\nğŸ—ï¸  åˆ›å»ºæ•°æ®é›†...")
    create_dataset_structure(output_dir)
    
    # å¤åˆ¶å›¾ç‰‡åˆ°æ•°æ®é›†
    copy_images_to_dataset(matched_data, output_dir)
    
    # åˆ›å»ºå…ƒæ•°æ®æ–‡ä»¶
    metadata_path = create_metadata_csv(matched_data, output_dir)
    
    # åˆ›å»ºæ•°æ®é›†ä¿¡æ¯
    create_dataset_info(matched_data, output_dir, metadata_path)
    
    # åˆ›å»ºREADME
    create_readme(output_dir, len(matched_data))
    
    print(f"\nğŸ“Š æ•°æ®é›†ç»Ÿè®¡:")
    print(f"  æ€»æ ·æœ¬æ•°: {len(matched_data)}")
    print(f"  å…ƒæ•°æ®æ–‡ä»¶: {metadata_path}")
    print(f"  æ•°æ®é›†ä½ç½®: {output_dir}")
    
    return True


def cleanup_temp_files(temp_dir: str, keep_temp: bool = False):
    """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
    if not keep_temp and os.path.exists(temp_dir):
        try:
            shutil.rmtree(temp_dir)
            print(f"ğŸ§¹ å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {temp_dir}")
        except Exception as e:
            print(f"âš ï¸  æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")
    elif keep_temp:
        print(f"ğŸ“ ä¿ç•™ä¸´æ—¶æ–‡ä»¶: {temp_dir}")


def validate_inputs(input_dir: str) -> bool:
    """éªŒè¯è¾“å…¥å‚æ•°"""
    if not os.path.exists(input_dir):
        print(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}")
        return False
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æ”¯æŒçš„æ–‡ä»¶
    xlsx_files, pdf_files = scan_files(input_dir)
    if not xlsx_files and not pdf_files:
        print(f"âŒ è¾“å…¥ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°XLSXæˆ–PDFæ–‡ä»¶: {input_dir}")
        return False
    
    return True


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="ä»PDFå’ŒXLSXæ–‡ä»¶åˆ›å»ºHugging Faceæ•°æ®é›†",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  %(prog)s                           # ä½¿ç”¨é»˜è®¤è·¯å¾„
  %(prog)s -i ./source -o ./my_dataset    # è‡ªå®šä¹‰è·¯å¾„
  %(prog)s --keep-temp               # ä¿ç•™ä¸´æ—¶æ–‡ä»¶ç”¨äºè°ƒè¯•
  %(prog)s --preview                 # ä»…é¢„è§ˆä¸åˆ›å»º
        """
    )
    
    # è·å–è„šæœ¬ç›®å½•
    script_dir = get_script_directory()
    
    parser.add_argument("-i", "--input", 
                       default=os.path.join(script_dir, "input"),
                       help="è¾“å…¥ç›®å½•è·¯å¾„ (é»˜è®¤: è„šæœ¬åŒçº§inputç›®å½•)")
    parser.add_argument("-o", "--output", 
                       default=os.path.join(script_dir, "dataset"),
                       help="è¾“å‡ºæ•°æ®é›†ç›®å½• (é»˜è®¤: è„šæœ¬åŒçº§datasetç›®å½•)")
    parser.add_argument("--temp-dir", 
                       help="ä¸´æ—¶å·¥ä½œç›®å½• (é»˜è®¤: ç³»ç»Ÿä¸´æ—¶ç›®å½•)")
    parser.add_argument("--keep-temp", action="store_true",
                       help="ä¿ç•™ä¸´æ—¶æ–‡ä»¶(ç”¨äºè°ƒè¯•)")
    parser.add_argument("--preview", action="store_true",
                       help="ä»…é¢„è§ˆè½¬æ¢ç»“æœï¼Œä¸åˆ›å»ºæ•°æ®é›†")
    
    args = parser.parse_args()
    
    # è·¯å¾„å¤„ç†
    input_dir = os.path.abspath(args.input)
    output_dir = os.path.abspath(args.output)
    
    if args.temp_dir:
        temp_dir = os.path.abspath(args.temp_dir)
        os.makedirs(temp_dir, exist_ok=True)
    else:
        temp_dir = tempfile.mkdtemp(prefix="dataset_creation_")
    
    print("=" * 80)
    print("ğŸš€ ä¸€é”®æ•°æ®é›†åˆ›å»ºå·¥å…·")
    print("=" * 80)
    print(f"è„šæœ¬ç›®å½•: {script_dir}")
    print(f"è¾“å…¥ç›®å½•: {input_dir}")
    print(f"è¾“å‡ºç›®å½•: {output_dir}")
    print(f"ä¸´æ—¶ç›®å½•: {temp_dir}")
    print(f"é¢„è§ˆæ¨¡å¼: {'æ˜¯' if args.preview else 'å¦'}")
    print()
    
    try:
        # éªŒè¯è¾“å…¥
        if not validate_inputs(input_dir):
            return 1
        
        # æ­¥éª¤1: è½¬æ¢æ–‡ä»¶
        success_count, temp_result = step1_convert_files(input_dir, temp_dir)
        
        if success_count == 0:
            print("âŒ æ²¡æœ‰æˆåŠŸè½¬æ¢ä»»ä½•æ–‡ä»¶")
            return 1
        
        if args.preview:
            print("\nğŸ‘€ é¢„è§ˆæ¨¡å¼ - è½¬æ¢å®Œæˆï¼Œä¸åˆ›å»ºæœ€ç»ˆæ•°æ®é›†")
            print(f"è½¬æ¢åçš„æ–‡ä»¶ä¿å­˜åœ¨: {temp_dir}")
            print("å¯ä»¥æ£€æŸ¥è½¬æ¢ç»“æœï¼Œç„¶åä½¿ç”¨ --keep-temp é€‰é¡¹é‡æ–°è¿è¡Œ")
            return 0
        
        # æ­¥éª¤2: åˆ›å»ºæ•°æ®é›†
        dataset_success = step2_create_dataset(temp_dir, output_dir)
        
        if not dataset_success:
            print("âŒ æ•°æ®é›†åˆ›å»ºå¤±è´¥")
            return 1
        
        print("\n" + "=" * 80)
        print("ğŸ‰ æ•°æ®é›†åˆ›å»ºå®Œæˆï¼")
        print("=" * 80)
        print(f"ğŸ“ æ•°æ®é›†ä½ç½®: {output_dir}")
        print(f"ğŸ“‹ åŒ…å«æ–‡ä»¶:")
        print(f"  â€¢ metadata.csv    - å…ƒæ•°æ®æ–‡ä»¶")
        print(f"  â€¢ images/         - å›¾ç‰‡ç›®å½•")
        print(f"  â€¢ dataset_info.json - æ•°æ®é›†ä¿¡æ¯")
        print(f"  â€¢ README.md       - ä½¿ç”¨è¯´æ˜")
        print()
        print("ğŸ’¡ ä½¿ç”¨å»ºè®®:")
        print(f"  cd {output_dir}")
        print(f"  head -3 metadata.csv")
        print(f"  ls images/ | head -5")
        print("=" * 80)
        
        return 0
        
    except KeyboardInterrupt:
        print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        return 1
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        return 1
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        cleanup_temp_files(temp_dir, args.keep_temp)


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code) 